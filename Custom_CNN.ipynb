{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom CNN for image classification\n",
    "### Team: 0Idee (Bono Federico, Cecere Nicola, Zanutto Davide)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries and set seed for reporducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "KNZotXHOapW8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429891880,
     "user_tz": -60,
     "elapsed": 4979,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 12:48:46.348548: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras.models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import splitfolders\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "metadata": {
    "id": "CvMKuJH0apW-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429894425,
     "user_tz": -60,
     "elapsed": 308,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set log levels\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "id": "bQIJQdcCapW_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429898793,
     "user_tz": -60,
     "elapsed": 214,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data import"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OSFbxo0DapXA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Splitting the main dataset into train and val\n",
    "dataset_dir = './dataset_split'\n",
    "\n",
    "if not (os.path.exists(dataset_dir)):\n",
    "    print('splitting')\n",
    "    splitfolders.ratio('./training_data_final', output=dataset_dir, seed=seed, ratio=(0.8, 0.2))\n",
    "\n",
    "# Setting dataset directories\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'val')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JVZpBO_bapXD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2829 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "aug_train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    brightness_range=(0.6, 1.4),\n",
    "    zoom_range=0.6,\n",
    "    fill_mode='reflect',\n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "aug_train_gen = aug_train_data_gen.flow_from_directory(\n",
    "    directory=training_dir,\n",
    "    target_size=(96, 96),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")"
   ],
   "metadata": {
    "id": "ilLddj5LapXG",
    "outputId": "e2f49ece-7c0b-446c-e1a1-2ab420d4b4eb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430279500,
     "user_tz": -60,
     "elapsed": 6,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 713 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data_gen = ImageDataGenerator(rescale=1 / 255.)\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(\n",
    "    directory=validation_dir,\n",
    "    target_size=(96, 96),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "### Parameters and configuration"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4Gc1EGSbapXG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "input_shape = (96, 96, 3)\n",
    "epochs = 200\n",
    "labels = ['Species1', 'Species2', 'Species3', 'Species4', 'Species5', 'Species6', 'Species7', 'Species8']\n",
    "\n",
    "# Weights are based on the number of samples and then fine-tuned on the train dataset\n",
    "class_weights = {0: 2., 1: 1., 2: 1., 3: 1., 4: 1., 5: 2., 6: 1., 7: 1.}"
   ],
   "metadata": {
    "id": "lvv6irhHapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430281738,
     "user_tz": -60,
     "elapsed": 1,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    # Input layer -------------------------------------------------------\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # First layer -------------------------------------------------------\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(input_layer)\n",
    "    conv1 = tfkl.BatchNormalization()(conv1)\n",
    "    pool1 = tfkl.MaxPooling2D()(conv1)\n",
    "\n",
    "    # Second layer -------------------------------------------------------\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool1)\n",
    "    conv2 = tfkl.BatchNormalization()(conv2)\n",
    "    pool2 = tfkl.MaxPooling2D()(conv2)\n",
    "\n",
    "    # Third layer -------------------------------------------------------\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool2)\n",
    "\n",
    "    # Fourth layer -------------------------------------------------------\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(conv3)\n",
    "    conv4 = tfkl.BatchNormalization()(conv4)\n",
    "    pool3 = tfkl.MaxPooling2D()(conv4)\n",
    "\n",
    "    # Fifth layer -------------------------------------------------------\n",
    "    conv5 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool3)\n",
    "    conv5 = tfkl.BatchNormalization()(conv5)\n",
    "    pool4 = tfkl.MaxPooling2D()(conv5)\n",
    "\n",
    "    # Sixth layer -------------------------------------------------------\n",
    "    conv6 = tfkl.Conv2D(\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool4)\n",
    "    conv6 = tfkl.BatchNormalization()(conv6)\n",
    "    pool5 = tfkl.MaxPooling2D()(conv6)\n",
    "\n",
    "    # Flattening layer -------------------------------------------------------\n",
    "    flattening_layer = tfkl.GlobalAvgPool2D(name='gap')(pool5)\n",
    "\n",
    "    # Dense layers -------------------------------------------------------\n",
    "    classifier_layer = tfkl.Dense(units=600, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                                  activation='relu')(flattening_layer)\n",
    "    hidden_layer = tfkl.Dense(units=258, name='Hidden_layer', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                              activation='relu')(classifier_layer)\n",
    "    dropout = tfkl.Dropout(0.3, seed=seed)(hidden_layer)\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                              name='output_layer')(dropout)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=tfk.losses.CategoricalCrossentropy(),\n",
    "        optimizer=tfk.optimizers.Adam(),\n",
    "        metrics=['accuracy', tfk.metrics.Precision(), tfk.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 5300M\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96, 96, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2D  (None, 512)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Classifier (Dense)          (None, 600)               307800    \n",
      "                                                                 \n",
      " Hidden_layer (Dense)        (None, 258)               155058    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 258)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 8)                 2072      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,185,058\n",
      "Trainable params: 2,183,074\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model (for data augmentation training)\n",
    "model = build_model(input_shape)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "    exps_dir = os.path.join('data_augmentation_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model checkpoint\n",
    "    # ----------------\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
    "                                                       save_weights_only=True,  # True to save only weights\n",
    "                                                       save_best_only=False)  # True to save only the best epoch\n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Visualize Learning on Tensorboard\n",
    "    # ---------------------------------\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "\n",
    "    # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "    # Early Stopping\n",
    "    # --------------\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "    # Learning Rate Scheduler --------------------------------------------\n",
    "    LRS_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    callbacks.append(LRS_callback)\n",
    "\n",
    "    return callbacks"
   ],
   "metadata": {
    "id": "QgDzFFTUapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430285936,
     "user_tz": -60,
     "elapsed": 204,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "89/89 [==============================] - 20s 171ms/step - loss: 2.1622 - accuracy: 0.3121 - precision: 0.4146 - recall: 0.1124 - val_loss: 3.0660 - val_accuracy: 0.1459 - val_precision: 0.1548 - val_recall: 0.1403 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "13/89 [===>..........................] - ETA: 11s - loss: 1.8570 - accuracy: 0.4135 - precision: 0.5000 - recall: 0.1635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9k/_qtc2s8x41xbrrfvcsrn72ym0000gn/T/ipykernel_31233/105247216.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Train the model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m history = model.fit(\n\u001B[0m\u001B[1;32m      6\u001B[0m     \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maug_train_gen\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1562\u001B[0m                         ):\n\u001B[1;32m   1563\u001B[0m                             \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1564\u001B[0;31m                             \u001B[0mtmp_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1565\u001B[0m                             \u001B[0;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1566\u001B[0m                                 \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    913\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    914\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 915\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    916\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    945\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    946\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 947\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    948\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    949\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2494\u001B[0m       (graph_function,\n\u001B[1;32m   2495\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2496\u001B[0;31m     return graph_function._call_flat(\n\u001B[0m\u001B[1;32m   2497\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[1;32m   2498\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1860\u001B[0m         and executing_eagerly):\n\u001B[1;32m   1861\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1862\u001B[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[1;32m   1863\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[1;32m   1864\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m       \u001B[0;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    498\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 499\u001B[0;31m           outputs = execute.execute(\n\u001B[0m\u001B[1;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m   \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[1;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[1;32m     56\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Create folders and callbacks and fit\n",
    "aug_callbacks = create_folders_and_callbacks(model_name='CNN_Aug')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=aug_train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=aug_callbacks,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights\n",
    ").history"
   ],
   "metadata": {
    "id": "EUdsjUfdapXI",
    "outputId": "be5340c2-af75-4003-8380-169b2370318e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431787144,
     "user_tz": -60,
     "elapsed": 1492245,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Save best epoch model\n",
    "model.save(\"data_augmentation_experiments/CNN_Aug_Best\")"
   ],
   "metadata": {
    "id": "up5di_mcapXI",
    "outputId": "9828dc0d-172e-446b-97fe-86433966240e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431799360,
     "user_tz": -60,
     "elapsed": 3030,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "### Confusion matrix, Accuracy, Precision and Recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 620ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 1s 508ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9k/_qtc2s8x41xbrrfvcsrn72ym0000gn/T/ipykernel_31233/4269517559.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mpred_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m500\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     \u001B[0mbatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_next_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_gen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0mtrue_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrue_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mpred_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred_label\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/9k/_qtc2s8x41xbrrfvcsrn72ym0000gn/T/ipykernel_31233/4269517559.py\u001B[0m in \u001B[0;36mget_next_batch\u001B[0;34m(generator)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mget_next_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mbatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_next_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalid_gen\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mtrue_label\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    155\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 156\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    157\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    158\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36mnext\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    166\u001B[0m         \u001B[0;31m# The transformation of images is not under thread lock\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m         \u001B[0;31m# so it can be done in parallel\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 168\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_batches_of_transformed_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    169\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    170\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_get_batches_of_transformed_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/DeepLearning/lib/python3.8/site-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36m_get_batches_of_transformed_samples\u001B[0;34m(self, index_array)\u001B[0m\n\u001B[1;32m    384\u001B[0m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_data_generator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_transform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    385\u001B[0m                 \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_data_generator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstandardize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 386\u001B[0;31m             \u001B[0mbatch_x\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    387\u001B[0m         \u001B[0;31m# optionally save augmented images to disk for debugging purposes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave_to_dir\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def get_next_batch(generator):\n",
    "    return next(generator)\n",
    "\n",
    "batch = get_next_batch(valid_gen)\n",
    "true_label = batch[1]\n",
    "pred_label = model.predict(batch[0])\n",
    "for i in range(0, 500):\n",
    "    batch = get_next_batch(valid_gen)\n",
    "    true_label = np.concatenate((true_label, batch[1]), axis=0)\n",
    "    pred_label = np.concatenate((pred_label, model.predict(batch[0])), axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdEAAAHeCAYAAADElTFOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfVxUZf4//tdxcIQGYWBDXBNMJxXxrnC3xDI+RpbLptViDlbstirWYrurFOpkgRICYaa72rIpgUL9AlpzZZdNN1YQ12623KzgY2owOR91GRFR4kbu5nz/8NdsptyI52I4x9dzH/N4MHOG6/3Oh/Xe93Wuc12SLMsyiIiI6KoNcHUCREREasUiSkRE1EssokRERL3EIkpERNRLLKJERES9xCJKRETUS26uTuD73PQ3uToFIlKJl4bOcHUKV2VFdYmrU7hq7a0nhY3ddqZK8TEH3jhK8TG7wk6UiIiol/pdJ0pERNcJR4erM7hm7ESJiIh6iZ0oERG5huxwdQbXjJ0oERFRL7ETJSIi13CovxNlESUiIpeQOZ1LRER0/WInSkRErsHp3Mv985//7PTaXXfdpXQ4IiIil1G8iBYUFKC8vBx33HHHZddYRImIyEkD90QVL6IbNmzA448/jpiYGIwa1bd7GBIRkYpwx6LL6XQ6pKeno62tTemhiYiI+hUhC4sCAgIuee9wODBgABcCExHRd2hgOldYZSssLERRURF27tyJO++8E6+//rqoUERERFfls88+Q3R09GWf7927F5GRkTCbzSgoKOh2HGFFNCcnB9OmTUNhYSH27duHkhL1naNHREQCORzKv3pg69ateP7559HS0nLJ521tbUhNTUVWVhZyc3ORn5+PM2fOdDmWsCLq7u4OADAYDNDr9WhvbxcVioiIVEiWHYq/eiIwMBCbNm267PPKykoEBgbC29sber0eU6ZMwccff9zlWMI2WwgICIDZbIbFYsHmzZsxduxYUaGIiIgAAPn5+cjPz3e+N5vNMJvNl3zn/vvvx4kTJy773YaGBgwePNj53mAwoKGhoct4wopoamoqGhsbYTAYMGHCBPj5+YkKRUREaiRgx6IrFc2e8vT0RGNjo/N9Y2PjJUX1SoRN5x47dgwxMTF44IEHsHPnTt4TJSKifs1kMuH48eM4d+4cWltb8cknn+C2227r8neEFdHk5GSkpqbCx8cHc+fOveL8MxERXcdkh/KvXvjLX/6C/Px8DBw4ECtXrsTChQsRFRWFyMhI+Pv7d/m7QjegHzFiBCRJgq+vLwwGg8hQREREPTZ8+HDnIyyzZ892fn7PPffgnnvu6fE4woqot7c38vLy0NzcjKKiInh5eYkKRUREasRt/zqXkpKCEydOwMfHB+Xl5Vi7dq2oUEREpEb9ZDr3WijeiVZXV2Po0KGoqalBZGSk8/O6ujoYjUalwxEREbmM4kU0OzsbFosFCQkJkCTpkms5OTlKhyMiIrXiodyXs1gsAIDMzExUVlYiODgYxcXFCAsLUzoUERGRSwm7JxofH4/Dhw8DAKxWK1auXCkqFBERqZEG7okKK6J2u915TzQmJganT58WFYqIiNTIRRvQK0lYEZUkCVarFQBgs9ng0MDcNxER0XcJe07UYrFg2bJlOHPmDIYMGYI1a9aICkVERCoky+p/TlRYEZ08eTJyc3Nx8uRJBAQEcMciIiLSHGFFdM+ePcjIyEBHRwdmzZoFSZIQGxsrKhwREamNCxYCKU3YPdHs7GwUFBTAaDQiNjYWxcXFokIREZEacWFR53Q6HfR6PSRJgiRJ8PDwEBWKiIjIJYRN506ZMgVxcXGw2+1ISEjAxIkTRYUiIiI10sB0rrAiGhcXh7KyMgQHB8NkMmHGjBmiQhEREbmEsCJaW1uLsrIyWK1W1NbWIiQkBN7e3qLCERGR2vAotM4tXboUJpMJ8fHxGD58OJYvXy4qFBERqZEGtv0T1okCwPz58wEAQUFB2L17t8hQREREfU5YER01ahR27dqFqVOnoqKiAkaj0bkN4MiRI0WFJSIitdDAdrDCimhVVRWqqqqQlZUFnU4Hg8HgPGOU54oSEZEWKF5EKyoqsGrVKhQUFKC0tBSJiYnw8vLCkiVLEB4ernQ4IiJSKw084qL4wqL09HSkpaVBr9dj48aNyMzMxI4dO7B161alQxEREbmU4p2ow+FAUFAQ7HY7mpubMX78eAAXj0YjIiJy4j3RKwzodnHI/fv3IzQ0FADQ1taGpqYmpUMREZGasYheLjQ0FFFRUaiurkZGRgZsNhuSkpIQERGhdCgiIiKXUryILl68GOHh4fD09IS/vz9sNhvMZjNmzpypdCgiIlIxHsrdCZPJ5Pw5MDAQgYGBIsIQERG5lNAdi4iIiDrFe6JERES9xOdEiYiIrl/sRImIyDU4nUtE5Dq/+XeSq1O4KiuGTXd1CqQwFlEiInINDdwTZRElIiLX0MB0LhcWERER9RI7USIicg0NTOeyEyUiIuoldqJEROQavCdKRER0/WInSkRErsFO9HItLS1444038Pbbb6O1tdX5eV5entKhiIhIzWSH8q8+pngRXb58OU6fPg2r1YpHH30U58+fBwD87W9/UzoUERGRSyk+nXv27Fn87ne/AwD8/e9/x69+9Sts27YNsiwrHYqIiNRMA9O5ihfRtrY2nD17Fr6+vrjvvvtw6tQpPPvss2hra1M6FBERkUspPp3729/+Fo899hjOnDkDAHjiiScwbtw4lJeXKx2KiIjUTAP3RCW5D+ZZHQ4H6urq8IMf/KDb77rpbxKdDhFpRPOp/a5O4ap4qPAUl/bWk8LGbt6ZpviYHg+vVHzMrgh7TrSwsBBFRUXYuXMn7rrrLvz5z38WFYqIiMglhBXRnJwcTJs2DYWFhSgtLUVJSYmoUEREpEYamM4VVkTd3d0BAAaDAXq9Hu3t7aJCERERuYSwIhoQEACz2YzIyEhs3rwZY8eOFRWKiIjUyOFQ/tXHhG37l5qaisbGRhgMBkyYMAF+fn6iQhERkRrxOdHOHTt2DImJiaivr8ecOXMwevRozJgxQ1Q4IiKiPidsOjc5ORmpqanw8fHB3LlzsWnTJlGhiIhIjWRZ+VcfE3oU2ogRIyBJEnx9fWEwGESGIiIi6nPCpnO9vb2Rl5eH5uZmFBUVwcvLS1QoIiJSIw3cExXWiaakpODEiRPw8fFBeXk51q5dKyoUERGRSyjeiVZXV2Po0KGoqalBZGSk8/O6ujoYjUalwxERkVppoBNVvIhmZ2fDYrEgISEBkiRdci0nJ0fpcEREpFYu2GFIaYoXUYvFAgDIzMxEZWUlgoODUVxcjLCwMKVDERERuZSwe6Lx8fE4fPgwAMBqtWLlyr7dWZ+IiPo5DexYJKyI2u125z3RmJgYnD59WlQoIiIilxBWRCVJgtVqBQDYbDY4NHADmYiIFKSBzRaEPSdqsViwbNkynDlzBkOGDMGaNWtEhSIiIjXSQHMlrIhOnjwZubm5OHnyJAICArhjERERaY6wIrpnzx5kZGSgo6MDs2bNgiRJiI2NFRWOiIjURgOdqLB7otnZ2SgoKIDRaERsbCyKi4tFhSIiInIJYZ2oTqeDXq+HJEmQJAkeHh6iQhERkRpxs4XOTZkyBXFxcbDb7UhISMDEiRNFhSIiIhWSHX2/mlZpwopoXFwcysrKEBwcDJPJxAO5iYhIc4QV0draWpSVlcFqtaK2thYhISHw9vYWFY6IiNSGC4s6t3TpUphMJsTHx2P48OFYvny5qFBEREQuIawTBYD58+cDAIKCgrB7926RoYiISG00sLBIWCc6atQo7Nq1C3a7HXv37oXRaITVanVuBUhERKR2wjrRqqoqVFVVISsrCzqdDgaDwXnGKM8VJSIicHXu5SoqKrBq1SoUFBSgtLQUiYmJ8PLywpIlSxAeHq50OCIiUisuLLpceno60tLSoNfrsXHjRmRmZmLHjh3YunWr0qGIiIiuisPhQEJCAsxmM6Kjo3H8+PFLrmdlZeFnP/sZIiMj8d5773U7nuKdqMPhQFBQEOx2O5qbmzF+/HgAF49GIyIicnJBJ1pcXIzW1lbk5+fj0KFDSEtLQ0ZGBgCgvr4eOTk5+Pvf/47m5mY89NBDmDlzZpfjKd6JurldrMv79+9HaGgoAKCtrQ1NTU1KhyIiIroqBw8exPTp0wEAt956K8rLy53XPDw8MGzYMDQ3N6O5ublHzZ/inWhoaCiioqJQXV2NjIwM2Gw2JCUlISIiQulQRESkZgIO0c7Pz0d+fr7zvdlshtlsdr5vaGiAp6en871Op0N7e7uzAfzhD3+In/70p+jo6MCTTz7ZbTzFi+jixYsRHh4OT09P+Pv7w2azwWw2d9sSExHRdUbAdO73i+b3eXp6orGx8TspOJwFtKysDKdPn8Y//vEPAMDChQsREhKCSZMmdTqekOdETSYT/P39AQCBgYEsoERE1C+EhISgrKwMAHDo0CGMGTPGec3b2xvu7u7Q6/UYNGgQBg8ejPr6+i7HE7pjERERUadc8JzozJkzceDAAURFRUGWZaSkpCA7OxuBgYEIDw/H+++/j3nz5mHAgAEICQnBnXfe2eV4kiwLmJS+Bm76m1ydAhGpRPOp/a5O4ap4DJvu6hSuWnvrSWFjN728SPExb3g2U/Exu8JOlIiIXEMDe+eyiBIRkWtw2z8iItdxVFe6OgW6zrGIEhGRS8jcO5eIiOj6xU6UiIhcQwP3RNmJEhER9RI7USIicg0+4kJERNRLnM4lIiK6frETJSIi1+AjLkRERNcvIZ3ol19+iRtuuAFDhw7Fli1bIEkSFixYAA8PDxHhiIhIjTRwT1TxIrp+/Xp89tlnaGhogJ+fH8aNGweDwYDnn38e69evVzocERGpFVfnXu7jjz9GXl4eGhsbMXv2bLz22msAgOjoaKVDERERuZTiRdThcODUqVMYNmwYNmzYAACor69Ha2ur0qGIiEjNNDCdq/jCouXLl+PXv/41HA4HJk+eDAD41a9+hSeffFLpUERERC6leCf6ox/9CDt27Ljks5ycHOh0OqVDERGRimnhFBdhz4kWFhZCp9OhtbUV69atw8KFC7Fw4UJR4YiISG04ndu5nJwcTJs2DYWFhSgtLUVJSYmoUERERC4hrBN1d3cHABgMBuj1erS3t4sKRUREasROtHMBAQEwm82IjIzE5s2bMXbsWFGhiIiIXEJYJ5qamorGxkYYDAZMmDABfn5+okIREZEacbOFzh07dgyJiYmor6/HnDlzMHr0aMyYMUNUOCIioj4nbDo3OTkZqamp8PHxwdy5c7Fp0yZRoYiISI0csvKvPib0KLQRI0ZAkiT4+vrCYDCIDEVERCojc2FR57y9vZGXl4fm5mYUFRXBy8tLVCgiIiKXEFZEU1JScOLECfj4+KC8vBxr164VFYqIiNSI07mXq66uxtChQ1FTU4PIyEjn53V1dTAajUqHIyIichnFi2h2djYsFgsSEhIgSdIl13JycpQOR0REasW9cy9nsVgAAJmZmaisrERwcDCKi4sRFhamdCgiIlIzLizqXHx8PA4fPgwAsFqtWLlypahQRERELiGsiNrtduc90ZiYGJw+fVpUKCIiUiMNLCwSVkQlSYLVagUA2Gw2ODQw901ERPRdwjZbsFgsWLZsGc6cOYMhQ4ZgzZo1okIREZEKybL674kKK6KTJ09Gbm4uTp48iYCAAO5YREREl9LAwiJhRXTPnj3IyMhAR0cHZs2aBUmSEBsbKyocERFRnxN2TzQ7OxsFBQUwGo2IjY1FcXGxqFBERKRGXFjUOZ1OB71eD0mSIEkSPDw8RIUiIiJyCWHTuVOmTEFcXBzsdjsSEhIwceJEUaGIiEiFtHCKi7AiGhcXh7KyMgQHB8NkMvFAbiIi0hxhRbS2thZlZWWwWq2ora1FSEgIvL29RYUjIiK10UAnKuye6NKlS2EymRAfH4/hw4dj+fLlokIREZEaOQS8+piwThQA5s+fDwAICgrC7t27RYYiIiLqc8KK6KhRo7Br1y5MnToVFRUVMBqNzm0AR44cKSosERGpBBcWdaGqqgpVVVXIysqCTqeDwWBwnjHKc0WJiEgLFC+iFRUVWLVqFQoKClBaWorExER4eXlhyZIlCA8PVzocERGplQY6UcUXFqWnpyMtLQ16vR4bN25EZmYmduzYga1btyodioiI1IwLiy7ncDgQFBQEu92O5uZmjB8/HsDFo9GIiIi0RPEi6uZ2ccj9+/cjNDQUANDW1oampialQxERkYpxYdEVhIaGIioqCtXV1cjIyIDNZkNSUhIiIiKUDkVERORSihfRxYsXIzw8HJ6envD394fNZoPZbMbMmTOVDkVERGrmgnuYShPyiIvJZHL+HBgYiMDAQBFhiIhIxbQwnSts2z8iIiKtE7rtHxERUac0MJ3LTpSIiKiX2IkSEZFLyBroRFlEiUi15JZGV6dA10IDRZTTuURERL3ETpSIiFxCC9O57ESJiIh6iZ0oERG5BjtRIiKi6xc7USIicgkt3BNlESUiIpfQQhHldC4REVEvCS+iW7duFR2CiIhUSHYo/+prik/nxsXFQZIkAIAsy/joo4/w5ZdfAgDWr1+vdDgiIiKXUbyIjhkzBvv27cNvfvMbDBgwAFVVVTCbzUqHISIitZMlV2dwzRQvok899RTGjRuHN998E0lJSfDy8sLtt9+udBgiIlI5LSwsErI6NywsDCNHjkR8fDzq6+tFhCAiInI5YY+4BAYGYtOmTThw4AAcDgcGDOBCYCIi+i/Zof7pXGGVrbCwECUlJfjmm29w55134vXXXxcVioiIyCWEFdGcnBxMmzYNf/nLX7Bv3z6UlJSICkVERCrER1y64O7uDgAwGAzQ6/Vob28XFYqIiFRI1sDqXGGdaEBAAMxmMyIjI7F582aMHTtWVCgiIqIecTgcSEhIgNlsRnR0NI4fP37J9X379mHevHl45JFHsHr1asiy3OV4wjrR1NRUNDY2wmAwYMKECfDz8xMVioiIVMgV06/FxcVobW1Ffn4+Dh06hLS0NGRkZAAAGhoasG7dOuTk5MDX1xdbt25FXV0dfH19Ox2v2070/fffR1lZGfbt24d7770Xf/nLX3qU6LFjxxATE4MHHngAO3fu5D1RIiJyuYMHD2L69OkAgFtvvRXl5eXOa59++inGjBmDl156CY8++ihuvPHGLgso0IMiumHDBtx8883IycnBW2+9hby8vB4lmpycjNTUVPj4+GDu3LnYtGlTj36PiIiuD7JDUvzVnYaGBnh6ejrf63Q655qduro6fPTRR3j22WexdetWbN++HVartcvxup3OdXd3xw9+8AO4ubnBz8/PuS9uT4wYMQKSJMHX1xcGg6HHv0dERNQb+fn5yM/Pd743m82XbD3r6emJxsZG53uHwwE3t4ul0Gg0YuLEic7bjz/60Y9w+PBhjBw5stN43RZRg8GARYsWwWw248033+y2tf2Wt7c38vLy0NzcjKKiInh5efXo94iI6PrQzZqdXvl+0fy+kJAQlJSUICIiAocOHcKYMWOc18aPH4+jR4/i7Nmz8PLywmeffYZ58+Z1GU+Su1l61NraCpvNhltuuQVHjx7FzTffDL1e3+0/SENDA/74xz/i6NGjMJlMePLJJ2E0Grv9PTf9Td1+h4gIABo+eNXVKVwVz9Alrk7hqrW3nhQ29vGQexUfc8S/i7u87nA4sHr1ahw9ehSyLCMlJQVlZWUIDAxEeHg4ioqKnJsDzZo1C4sXL+5yvE6L6Pr16zuduo2Li+t0wOrqagwdOvSK88hdtcTfYhElop5iERVPa0VUaZ1O544aNapXA2ZnZ8NisSAhIeGyIpyTk9OrMYmISHu0sHdut9O57e3t2LlzJ06dOoWpU6di9OjRPbov2tLSgsrKSgQHB6O4uBhhYWEYOHBgt7/HTpSIeoqdqHgiO9Gvb52p+Jg3H3pP8TG70u0jLomJiTh16hTef/99NDY2YsWKFT0aOD4+HocPHwYAWK1WrFy58toyJSIiTZFl5V99rdsiarPZ8Nvf/hZ6vR733HMPvvnmmx4NbLfbERkZCQCIiYnB6dOnry1TIiLSFFc8J6q0botoR0cHzp49C0mS0NDQ0ONzQSVJci4ustlscDg0cIQ5ERHRd3T7nOjSpUsxf/581NTUwGw247nnnuvRwBaLBcuWLcOZM2cwZMgQrFmz5pqTJSIi7dDCKS7dLiwCLj5X8+0mvFezY9E333yDkydPIiAgoMc7FnFhERH1FBcWiSdyYVHlhPsVH9NUvkfxMbvSbSe6b98+JCUlwcvLC01NTUhKSsIdd9zR7cB79uxBRkYGOjo6MGvWLEiShNjYWEWSJiIi9XPFKS5K6/YG5+bNm/H2229j586deOONN7B+/foeDZydnY2CggIYjUbExsaiuLhvH4AlIqL+zSFLir/6WrdF1GAwOJ8L9fPzg4eHR48G1ul00Ov1kCQJkiT1+PeIiIjUotPp3FdeeQXAxdW5Tz75JKZMmYLPP/+8R/vmAsCUKVMQFxcHu92OhIQETJw4UZmMiYhIE7SwsKjTIvrtPrff3e82PDy8xwPHxcWhrKwMwcHBMJlMmDFjxjWkSURE1P90WkQffvhhABe3/fviiy/Q3t4OWZZ7vGlCbW0tysrKYLVaUVtbi5CQEHh7eyuTNRERqZ4W9s7tdnXu008/jba2Npw+fRodHR0YMmQIHnjggW4HXrp0KSIiIjB37lwcPHgQy5cvx2uvvaZI0kRERP1BtwuL6urq8Prrr2PSpEl455130NLS0uPB58+fj6CgIDz22GNoamq6pkSJiEhbtLB3bredqLu7OwCgubkZ7u7uPd5sYdSoUdi1axemTp2KiooKGI1G5zaAPTlXlIiItO26mM697777sHnzZgQFBWHevHm44YYbejRwVVUVqqqqkJWVBZ1OB4PB4DxjlOeKEhGRFnRbRB977DHnz2FhYbj55pu7/H5FRQVWrVqFgoIClJaWIjExEV5eXliyZMlVre4lIiJtc8XmCErrtIjGxcV1OnXb1a5F6enpSEtLg16vx8aNG5GZmYkRI0Zg0aJFLKJERKQpnRbRqKioXg3ocDgQFBQEu92O5uZmjB8/HgCuauN6IiLSPk1vtnD77bf3bkC3i0Pu378foaGhAIC2tjauziUioku4YjWt0rq9J3q1QkNDERUVherqamRkZMBmsyEpKQkRERFKhyIiInIpxYvo4sWLER4eDk9PT/j7+8Nms8FsNmPmzJlKhyIiIhXT9MIii8XS6S+lpqZ2OajJZHL+HBgYiMDAwF6kRkRE1L91umNRREQEIiIicP78eYwaNQpz587F2LFj0dra2pf5ERGRRsmypPirr3XaiU6fPh3AxcO1Y2JiAFw83uyXv/xl32RGRESapoWFRd3undvU1IQPPvgADQ0N2L9//1XtnUtERKRl3S4sWrt2LdatW4evv/4at9xyC1566aW+yIuIiDRO0wuLvmUymbBixQocP34cQUFB8Pf374u8iIi6JQ2+0dUp0HWu2yL6xhtv4L333sP58+fx8MMP4/jx40hISOiL3IiISMO0sGNRt/dEi4qKkJ2djcGDB+MXv/gFPvvss77Ii4iIqN/rthOVZRmSJDn3vtXr9cKTIiIi7bsu7on+9Kc/xWOPPYZTp04hJiYG9957b1/kRUREGqeBJ1y6L6Lz58/HtGnTcPToUYwcORLDhg3ri7yIiIj6vU7vidbU1MBqteLRRx+FTqdDUFAQBg4ciAULFvRlfkREpFEOWVL81dc67UQ/++wzbN++HVarFQkJCZBlGQMGDMBdd93Vl/kRERH1W50W0XvvvRf33nsv9u3bh9tvvx0eHh6w2+18TpSIiBRxXTzi8sUXXyAjIwPAxd2LtmzZ0uX3P/nkEwCAw+HAm2++ieeffx5vvfUWOjo6FEiXiIi0wiHg1de6LaJ79+5FXFwcAOD3v/899u7d2+X3f//73wMA1q1bhyNHjmDmzJmw2WxITk5WIF0iIqL+o9vVuZIkobW1FXq9Hm1tbZB7uO3+559/jjfffBMAEBYWhujo6GvLlIiINEWG+qdzuy2iUVFRmD17NsaMGYOqqiosWrSoy+//5z//wXvvvYfBgwfjxIkTGD58OOx2Oy5cuKBY0kRERP1Bt0X0kUceQXh4OP7v//4PAQEB8PX17fL7K1asQHl5OTo6OlBcXIzIyEhERUVh7dq1iiVNRETq59DAbgudFtE//OEPiI2NRVxcnHPLv2+tX7++0wG/XdX7Xe+99x7c3Lqt10REdB1xaHk695577gFwcTq3NwoLC6HT6dDa2op169Zh4cKFWLhwYe+yJCIi6oc6XZ375Zdf4s9//jNOnTp12asncnJyMG3aNBQWFqK0tBQlJSWKJU1EROonQ1L81dc67UQrKysBXNy5yN3dHbfddhu++OILtLe346GHHup2YHd3dwCAwWCAXq9He3u7QikTERH1D50W0WeeeQYAsHDhwks2WOjp3rkBAQEwm82wWCzYvHkzxo4de42pEhGRlrhicwSldbva5+zZs6ivr4eXlxfq6upw7ty5Hg2cmpqKxsZGGAwGTJgwAX5+ftecLBERUX/SbRF96qmn8NBDD8Hb2xvffPMNXnjhhR4NfOzYMSQmJqK+vh5z5szB6NGjMWPGjGtOmIiItOG62Gzh/vvvR3h4OGpqanDjjTdi4MCBPRo4OTkZqampeP755zF37lwsWrSIRZSIiJyui+ncjz/+GGvWrEFHRwdmzZqFYcOG4ZFHHunR4CNGjIAkSfD19YXBYLjmZImIiPqTbjeg37hxI9544w3ceOONeOqpp/DWW2/1aGBvb2/k5eWhubkZRUVF8PLyuuZkiYhIO66LU1wGDBgAo9EISZIwaNCgHneUKSkpOHHiBHx8fFBeXs5t/4iISHO6nc4NDAzE+vXrce7cOWzZsgXDhg3r8vvV1dUYOnQoampqEBkZ6fy8rq4ORqPx2jMmIiJNuC4WFiUmJmLHjh2YMmUKPDw88OKLL3b5/ezsbFgsFiQkJFy2525OTs61ZUtERJrhUH8N7dkjLllZWT0e0GKxAHSqm6AAACAASURBVAAyMzNRWVmJ4OBgFBcXIywsrPdZEhER9UPd3hP18vLCP/7xD1RWVsJqtcJqtfZo4Pj4eBw+fBgAYLVasXLlymvLlIiINMUBSfFXX+u2E62trcW2bduc7yVJ6tG0rN1ud94TjYmJQXR0dO+zJCIi6oe6LKINDQ3YsmULPDw8rnpgSZJgtVoxcuRI2Gw2OBxaeKyWiIiUooEzuTsvom+88QaysrLg5uaGF154AdOnT7+qgS0WC5YtW4YzZ85gyJAhWLNmzTUnS0RE2qGF1qrTIvrXv/4Vu3fvRkNDA5YvX37VRXTy5MnIzc3FyZMnERAQwB2LiIhIczotonq9Hnq9Hr6+vmhra7vqgffs2YOMjAzndoGSJCE2NvaakiUiIu1wSOp/xqXb1bkAIMtXP3OdnZ2NgoICGI1GxMbGori4+KrHICIi6s867US/+uorPPPMM5Bl2fnzt9avX9/twDqdDnq9HpIkQZKkXi1OIiIi7dL0wqKNGzc6f46KirrqgadMmYK4uDjY7XYkJCRg4sSJvcuQiIion+q0iN5+++3XNHBcXBzKysoQHBwMk8nEs0SJiOgSml6de61qa2tRVlYGq9WK2tpahISEwNvbW1Q4IiJSGS3sndujhUW9sXTpUphMJsTHx2P48OFYvny5qFBEREQuIawTBYD58+cDAIKCgrB7926RoYiISGVcsdet0oR1oqNGjcKuXbtgt9uxd+9eGI3Gq9rAnoiIqL8T1olWVVWhqqoKWVlZ0Ol0MBgMzjNGea4oERFp+hGX3qqoqMCqVatQUFCA0tJSJCYmwsvLC0uWLEF4eLjS4YiISKW4sOgK0tPTkZaWBr1ej40bNyIzMxM7duzA1q1blQ5FRETkUop3og6HA0FBQbDb7Whubsb48eMBXDwajYiI6FtaeE5U8U7Uze1iXd6/fz9CQ0MBAG1tbWhqalI6FBERkUsp3omGhoYiKioK1dXVyMjIgM1mQ1JSEiIiIpQORUREKsaFRVewePFihIeHw9PTE/7+/rDZbDCbzZg5c6bSoYiISMVcsbDI4XBg9erVOHLkCPR6PZKTkzFixIjLvvNtLft2v4POCHnExWQyOX8ODAxEYGCgiDBERERXpbi4GK2trcjPz8ehQ4eQlpaGjIyMS76zceNG1NfX92g8oTsWERERdcYVC4sOHjyI6dOnAwBuvfVWlJeXX3J99+7dkCTJ+Z3uCNuxiIiIqK/l5+fjZz/7mfOVn59/yfWGhgZ4eno63+t0OrS3twMAjh49ir/+9a/47W9/2+N47ESJiMglRHSiZrMZZrO50+uenp5obGz8bw4Oh/Opkj//+c+w2+34xS9+gZMnT2LgwIG46aabcPfdd3c6HosoERFdN0JCQlBSUoKIiAgcOnQIY8aMcV777mljmzZtwo033thlAQVYRIno/zdQp77/HPx/M/7o6hToGsguWJ07c+ZMHDhwAFFRUZBlGSkpKcjOzkZgYGCvtqZV3781RESkCa5YWDRgwAAkJSVd8tl3nyj51q9//euejadIVkRERNchdqJEROQS3DuXiIjoOsZOlIiIXIJ75xIREfUSD+UmIiK6jrETJSIil+DCIiIiouuY4p3o+fPn8fXXX2PSpEnYuXMnysvLccstt2DevHnO/QmJiIjYiV5BXFwcTp8+jXXr1uHgwYOYNm0ajh8/jhUrVigdioiIVEwW8OprireGra2tmDlzJnJycpCbmwsAuPfeexEVFaV0KCIiIpdSvBN1c3PD559/jpCQEHz88ccALh6COmAAb78SEdF/OSTlX31N8U50zZo1eOGFF3D27Fm89tpr8PT0xM0334zk5GSlQxEREbmU4kU0MDAQ27dvR0tLC86dOwej0YiBAweyEyUioktwYVEX9uzZg08++QR/+9vfcNddd+H1118XFYqIiMglhBXRnJwcTJs2DYWFhSgtLUVJSYmoUEREpEJcndsFd3d3AIDBYIBer0d7e7uoUEREpEIODWxBL6wTDQgIgNlsRmRkJDZv3oyxY8eKCkVEROQSwjrR1NRUNDY2wmAwYMKECfDz8xMVioiIVEgLC4uEFdFjx44hMTER9fX1mDNnDkaPHo0ZM2aICkdERNTnhE3nJicnIzU1FT4+Ppg7dy42bdokKhQREakQFxZ1Y8SIEZAkCb6+vjAYDCJDERGRymhhOldYJ+rt7Y28vDw0NzejqKgIXl5eokIRERG5hLAimpKSghMnTsDHxwfl5eVYu3atqFBERKRC3Dv3CqqrqzF06FDU1NQgMjLS+XldXR2MRqPS4YiIiFxG8SKanZ0Ni8WChIQESNKl/7cgJydH6XBERKRSWthsQfEiarFYAACZmZmorKxEcHAwiouLERYWpnQoIiJSMfWXUIH3ROPj43H48GEAgNVqxcqVK0WFIiIicglhRdRutzvvicbExOD06dOiQhERkQo5BLz6mrAiKkkSrFYrAMBms8Hh0MITQURERP8lbLMFi8WCZcuW4cyZMxgyZAjWrFkjKhQREakQFxZ1YfLkycjNzcXJkycREBDAHYuIiOgS6i+hAovonj17kJGRgY6ODsyaNQuSJCE2NlZUOCIioj4n7J5odnY2CgoKYDQaERsbi+LiYlGhiIhIhbiwqAs6nQ56vR6SJEGSJHh4eIgKRURE5BLCpnOnTJmCuLg42O12JCQkYOLEiaJCERGRCnFhURfi4uJQVlaG4OBgmEwmHshNRESaI6yI1tbWoqysDFarFbW1tQgJCYG3t7eocEREpDLq70MF3hNdunQpTCYT4uPjMXz4cCxfvlxUKCIiUiEtLCwS1okCwPz58wEAQUFB2L17t8hQREREfU5YER01ahR27dqFqVOnoqKiAkaj0bkN4MiRI0WFJSIilZA1MKErrIhWVVWhqqoKWVlZ0Ol0MBgMzjNGea4oERFpgeJFtKKiAqtWrUJBQQFKS0uRmJgILy8vLFmyBOHh4UqHIyIildLCsSSKF9H09HSkpaVBr9dj48aNyMzMxIgRI7Bo0SIWUSIicuJzolfgcDgQFBQEu92O5uZmjB8/HsDFo9GIiIi0RPEi6uZ2ccj9+/cjNDQUANDW1oampialQxERkYqpvw8VUERDQ0MRFRWF6upqZGRkwGazISkpCREREUqHIiIicinFi+jixYsRHh4OT09P+Pv7w2azwWw2Y+bMmUqHIiIiFeM90U6YTCbnz4GBgQgMDBQRhoiIVEwLq3OFbftHRESkdUK3/SMiIuqMFnYsYidKRETUS+xEiYjIJbRwT5RFlIgAAG0d7a5O4ao9Wva0q1O4KjHjSlydAimMRZSIiFxCC/dEWUSJiMgltDCdy4VFREREvcROlIiIXMIhq386l50oERFRL7ETJSIil1B/H8oiSkRELqKFDeg5nUtERNRLihfRV155Bc3NzUoPS0REGiML+F9fU7yIvvPOO4iOjsaHH36o9NBERET9iuJFdOTIkdiwYQO2b9+On//85/jrX/+K8+fPKx2GiIhUziHg1dcUX1gkSRICAgKQkZGBI0eOoLCwEFlZWaitrcW+ffuUDkdERCqlhYVFihdR+TsPz44dOxbx8fFKhyAiIuoXFC+iubm5l33mcDgwYAAXAhMR0X9pYQN6YZWtsLAQRUVF2LlzJ+688068/vrrokIRERG5hLAimpOTg2nTpqGwsBD79u1DSQnP0SMiov/SwsIiYUXU3d0dAGAwGKDX69Herr4Df4mIiLoirIgGBATAbDYjMjISmzdvxtixY0WFIiIiFZJlWfFXXxO2d25qaioaGxthMBgwYcIE+Pn5iQpFREQqxEdcunDs2DEkJiaivr4ec+bMwejRozFjxgxR4YiIiPqcsOnc5ORkpKamwsfHB3PnzsWmTZtEhSIiIhXSwsIioUehjRgxApIkwdfXFwaDQWQoIiKibjkcDqxevRpHjhyBXq9HcnIyRowY4by+bds2FBUVAQDCwsLw9NNPdzmesE7U29sbeXl5aG5uRlFREby8vESFIiIiFXLFKS7FxcVobW1Ffn4+nnnmGaSlpTmv/d///R8KCwuRl5eHgoIC/POf/8SXX37Z5XjCimhKSgpOnDgBHx8flJeXY+3ataJCERGRCjkgK/7qzsGDBzF9+nQAwK233ory8nLntaFDhyIzMxM6nQ6SJKG9vR2DBg3qcjzFp3Orq6sxdOhQ1NTUIDIy0vl5XV0djEaj0uGIiIic8vPzkZ+f73xvNpthNpud7xsaGuDp6el8r9Pp0N7eDjc3NwwcOBC+vr6QZRnp6ekIDg7GyJEju4yneBHNzs6GxWJBQkICJEm65FpOTo7S4YiISKVEPNf5/aL5fZ6enmhsbHS+dzgccHP7bylsaWnBc889B4PBgMTExG7jKV5ELRYLACAzMxOVlZUIDg5GcXExwsLClA5FRER0VUJCQlBSUoKIiAgcOnQIY8aMcV6TZRmxsbG44447sHjx4h6NJ2x1bnx8PMLCwhAcHAyr1Yp3330X69evFxWOiIhUxhWPpMycORMHDhxAVFQUZFlGSkoKsrOzERgYCIfDgX/9619obW3F/v37AQBxcXG47bbbOh1PWBG12+3Oe6IxMTGIjo4WFYqIiFTIFUehDRgwAElJSZd8ZjKZnD9/8cUXVzeeIlldgSRJsFqtAACbzQaHwxX/n4OIiEgcYZ2oxWLBsmXLcObMGQwZMgRr1qwRFYqIiFSIe+d2YfLkycjNzcXJkycREBDAHYuIiEhzhBXRPXv2ICMjAx0dHZg1axYkSUJsbKyocEREpDKuOLpMacLuiWZnZ6OgoABGoxGxsbEoLi4WFYqIiMglhHWiOp0Oer0ekiRBkiR4eHiICkVERCrEe6JdmDJlCuLi4mC325GQkICJEyeKCkVERCrkikdclCasiMbFxaGsrAzBwcEwmUw8kJuIiDRHWBGtra1FWVkZrFYramtrERISAm9vb1HhiIhIZRxcWNS5pUuXwmQyIT4+HsOHD8fy5ctFhSIiInIJYZ0oAMyfPx8AEBQUhN27d4sMRUREKqP+PlRgER01ahR27dqFqVOnoqKiAkaj0bkNYHfnsxERkfZxdW4XqqqqUFVVhaysLOh0OhgMBucZozxXlIiItEDxIlpRUYFVq1ahoKAApaWlSExMhJeXF5YsWYLw8HClwxERkUppoRNVfGFReno60tLSoNfrsXHjRmRmZmLHjh3YunWr0qGIiIhcSvFO1OFwICgoCHa7Hc3NzRg/fjyAi0ejERERfUsLe+cqXkTd3C4OuX//foSGhgIA2tra0NTUpHQoIiJSMS1M5ypeRENDQxEVFYXq6mpkZGTAZrMhKSkJERERSociIiJyKcWL6OLFixEeHg5PT0/4+/vDZrPBbDZj5syZSociIiIV4965nTCZTM6fAwMDERgYKCIMERGRSwndsYiIiKgzWlhYJGzvXCIiIq1jJ0pERC7B1blERES9pIXpXBZRIgIADNSp7z8HcnWlq1Og65z6/q0hIiJN0MJ0LhcWERER9RI7USIicglutkBERNRLDg0sLOJ0LhERUS+xEyUiIpfQwnQuO1EiIqJeYidKREQuoYV7okKK6LFjxzBgwACYTCa8/vrrqK+vx6JFizB48GAR4YiISIW0MJ2reBH93e9+h48++ggtLS0YNmwYAgMD4efnh5UrV+LVV19VOhwREZHLKF5EP/jgA+Tl5aG1tRUPPPAANm3aBAD4xz/+oXQoIiJSMU7nXkFbWxuqqqpQV1eHuro61NTUwMPDAy0tLUqHIiIicinFi+gzzzyDZ555BsHBwViyZAkefPBBGAwGrFixQulQRESkYrwnegXTpk3Dzp07ne8jIyPh7u6OgQMHKh2KiIjIpYQ94lJYWAidTofW1lasW7cOCxcuxMKFC0WFIyIildHCPVFhmy3k5ORg2rRpKCwsRGlpKUpKSkSFIiIiFZIF/K+vCSui7u7uAACDwQC9Xo/29nZRoYiIiFxCWBENCAiA2WxGZGQkNm/ejLFjx4oKRUREKiTLDsVffU3YPdHU1FQ0NjbCYDBgwoQJ8PPzExWKiIjIJYQV0WPHjiExMRH19fWYM2cORo8ejRkzZogKR0REKuPQwCMuwqZzk5OTkZqaCh8fH8ydO9e5cxEREREAyLKs+KuvCT0KbcSIEZAkCb6+vjAYDCJDERER9Tlh07ne3t7Iy8tDc3MzioqK4OXlJSoUERGpEKdzu5CSkoITJ07Ax8cH5eXlWLt2rahQRERELqF4J1pdXY2hQ4eipqYGkZGRzs/r6upgNBqVDkdERCrlinuYSlO8iGZnZ8NisSAhIQGSJF1yLScnR+lwRESkUlrY9k/xImqxWAAAmZmZqKysRHBwMIqLixEWFqZ0KCIiIpcSdk80Pj4ehw8fBgBYrVasXLlSVCgiIlIh7p3bBbvd7rwnGhMTg9OnT4sKRURE5BLCiqgkSbBarQAAm80Gh6Pv9zQkIqL+SwubLQh7TtRisWDZsmU4c+YMhgwZgjVr1ogKRURE5BLCiujkyZORm5uLkydPIiAggDsWERHRJbSw2YKwIrpnzx5kZGSgo6MDs2bNgiRJiI2NFRWOiIhURgvPiQq7J5qdnY2CggIYjUbExsaiuLhYVCgiIiKXENaJ6nQ66PV6SJIESZLg4eEhKhQREamQFjZbENaJTpkyBXFxcbDb7UhISMDEiRNFhSIiInIJYZ1oXFwcysrKEBwcDJPJxAO5iYjoElq4JyqsiNbW1qKsrAxWqxW1tbUICQmBt7e3qHBERKQyWlidK2w6d+nSpTCZTIiPj8fw4cOxfPlyUaGIiIhcQlgnCgDz588HAAQFBWH37t0iQxERkcpoYTpXWCc6atQo7Nq1C3a7HXv37oXRaITVanVuBUhERKR2wjrRqqoqVFVVISsrCzqdDgaDwXnGKM8VJSIiLTziongRraiowKpVq1BQUIDS0lIkJibCy8sLS5YsQXh4uNLhiIhIpVxxdJnSFJ/OTU9PR1paGvR6PTZu3IjMzEzs2LEDW7duVToUERGRSyneiTocDgQFBcFut6O5uRnjx48HcPFoNCIiom9pYTpX8U7Uze1iXd6/fz9CQ0MBAG1tbWhqalI6FBERkUsp3omGhoYiKioK1dXVyMjIgM1mQ1JSEiIiIpQORUREKqaFR1wUL6KLFy9GeHg4PD094e/vD5vNBrPZjJkzZyodioiIyKWEPOJiMpmcPwcGBiIwMFBEGCIiUjEtrM4VumMRERFRZ7QwnStsxyIiIiKtYxElIiKXkGVZ8Vd3HA4HEhISYDabER0djePHj19yvaCgAD/72c8wb948lJSUdDsep3OJiOi6UVxcjNbWVuTn5+PQoUNIS0tDRkYGAKCmpga5ubnYsWMHWlpa8Oijj+LOO++EXq/vdDx2okRE5BKygFd3Dh48iOnTpwMAbr31VpSXlzuvff7557jtttug1+sxePBgBAYG4ssvv+xyvH7Xiba3nnR1CkREQrS3PubqFPoVEf+9z8/PR35+vvO92WyG2Wx2vm9oaICnp6fzvU6nQ3t7O9zc3NDQ0IDBgwc7rxkMBjQ0NHQZr98VUSIiot76ftH8Pk9PTzQ2NjrfOxwO505737/W2Nh4SVG9Ek7nEhHRdSMkJARlZWUAgEOHDmHMmDHOa5MmTcLBgwfR0tKCb775BpWVlZdcvxJJ1sKDOkRERD3gcDiwevVqHD16FLIsIyUlBWVlZQgMDER4eDgKCgqQn58PWZbx5JNP4v777+9yPBZRIiKiXuJ0LhERUS+xiBIREfVSv16du2XLFrz//vtob2+HJElYsWIFJkyYcE1jrl27Fr/85S8xbNiwq/q9jo4OLFu2DHPnzsXdd9/d73P+4IMPsHHjRri5ueEHP/gBXnrpJXh4ePTrnD/55BO89NJLkCQJP/7xjxEfH9+v8/3WH//4Rxw5cgQbNmzo9Dv9Jef33nsPL730En74wx8CAH7961/j9ttv79c5Hz9+HImJiWhra4Ner8crr7wCHx+ffptvdHS08+eqqio8/PDDePbZZ6/43f6S8/vvv4+XX34Zbm5uCA0NxbJly64ph+uK3E8dO3ZMNpvNssPhkGVZlv/3f/9Xnj17tktyOX78uGw2m+X/+Z//kfft29fp9/pTzvfdd59cU1Mjy7Isv/zyy/L27duv+L3+lPPDDz8s22w2WZZl+fHHH5crKiou+05/yleWZbm0tFQ2m83y0qVLO/1Of8r5lVdekXfv3t3t9/pTztHR0fKnn34qy7Is7969W/73v/992Xf6U77fstls8sMPPyw3NDRc8Xp/yvnBBx+Ujx07JjscDjkqKkr+8ssvXZKHGvXbTnTw4ME4deoU/vSnP+Huu+/GuHHj8Kc//QnR0dEYOXIkrFYrZFnGhg0b4Ofnh/Xr1+OTTz6Bw+HAE088gZ/85Cf47LPPkJKSAofDAX9/f7z88suIiYnB6tWrMWTIEKxatQp1dXUAgOeffx5jx46FxWLB8ePHceHCBfz85z/HQw89hKamJqxduxZbt25VTc65ubm48cYbAQDt7e0YNGhQv8+5oKAAbm5uaGxsRENDA2644YZ+ne/x48eRn5+P3/zmN3j77bdV8feioqIChw8fxvbt2zFp0iQ8++yzzmfk+mPOs2bNwtmzZ1FSUoL169djwoQJV+zq+ku+Dz30kDOntWvXIj4+HgaDod//vRg3bhzOnTuHtrY2tLS0QKfTdfr3mb7HdfW7e+Xl5fLKlSvlsLAw+f7775d3794tP/744/LOnTtlWZblN954Q37xxRfl0tJSZydw4cIFec6cOfL58+flOXPmyF999ZUsy7JcUFAgl5eXy48//rj81Vdfyenp6fKbb74py7IsW61WOSoqSv7mm2/k8PBwuba2Vq6trZULCwsvyWfFihVddqL9Mec9e/bIDz/8sHzhwgVV5Pzpp5/KM2bMkBctWiQ3Nzf323wbGhrkBQsWyDU1NfKHH37YZSfaX3KWZVnOysqSbTab7HA45BdeeEHOzc3t1zlXV1fLY8aMkT/44APZ4XDIFotFfvvtt/ttvt86fPiw/Pjjj3f5d6I/5ZydnS1PmTJFDg8Pl2NjY+WOjo5uc6eL+m0nevz4cXh6eiI1NRUA8MUXXyAmJgZ+fn6YOnUqgIsPze7duxf+/v6oqKhw3otob2/HyZMncebMGecB4Y888sgl4x89ehQffvgh3n33XQDA+fPn4enpieeeew4vvPACGhoaMGfOHFXnvG3bNuzevRuZmZmddqL9Ledbb70Ve/fuxYYNG7Blyxb85je/6Zf5HjhwADU1NVi2bBnq6+tx+vRpbNmyBYsXL+7Xf8aRkZHw8vICAISHh2PPnj2X5dufcvb29obBYHDGnDFjBg4cOIC5c+f2y3y/VVhYeNkY/fXPuL6+Hq+99hqKiorg7++P9PR0ZGVlYdGiRV3mTxf12yJ65MgR5OfnIyMjA3q9HiNHjoSXlxd0Oh3Ky8sxdOhQ/Pvf/8Ytt9yCUaNG4Y477sCLL74Ih8OBP/zhDwgICMCQIUPw9ddf4+abb8aWLVswcuRI5/ijRo3CnDlzMHv2bNTW1uLtt9/G6dOnUVFRgVdffRUtLS0ICwvDgw8+eMXprv6e89atW1FRUYFt27bB3d293+c8Z84c/OIXv0BGRobzP5ytra39Nt9//vOfuO+++wAAH330EfLy8q5YQPtTznPmzMGcOXOQl5eHoUOH4oMPPsD48eP7dc4PPvggbr75ZnzyySf40Y9+hI8//hijR4/u1/m6ubnhww8/RExMTGf/2vWrnGfPno0bbrjBeftkyJAhOHv2bJe503/12yJ63333obKyEnPnzsUNN9wAWZaxfPlybN++HTt37sS2bdvg4eGB9PR0GI1G/Otf/8Kjjz6KpqYm3HvvvfD09MSaNWvw3HPPYcCAAfDz88MTTzyBnJwcAMBTTz2FVatWoaCgAA0NDXj66afh5+eHmpoaREVFYcCAAViwYEGPC2h/yvncuXN49dVXERwc7PwX+Sc/+QkeffTRfpvzwIEDsWDBAsTExECv18PPzw/Jycn9Nl81/r0YOHAgkpOT8fTTT8Pd3R0mkwnz5s3r1zm7ubkhJSUFa9asQUdHB4YPH37Fe6L9KV/g4pFaV1pB3B9z1uv1WLlyJRYsWIBBgwZh8ODBSEtL6/Hf7+ue62aSe+fb+X41Yc7iqS1fWWbOfUFt+cqyOnO+nnGzBSIiol7i3rlERES9xE6UiIiol1hEiYiIeolFlIiIqJf67SMuRCKlpaWhoqICNTU1uHDhAgICAuDj44Pf//731zz2O++8g6qqqk43Hd+0aRNuvPFGzJ8/v9uxrua7RNT3WETpurRy5UoA3Rc8IqKusIgSfcfKlStx7tw5nDt3DgsXLsTf/vY35xFnd955Jw4cOID//Oc/eOGFF9DS0oJBgwbhxRdfdB4t9n3r169HeXk5zp07h6CgIOcWb8XFxXj33Xdx4cIFPP/885g0aRLeffddbNu2DQMGDMCUKVMuKexnz57F0qVLIcsyWlpasGbNGowbN078HwgRdYlFlOh7pk6diieeeAIfffTRFa+/9NJLiI6ORlhYGD744AO8/PLLWL9+/WXfa2hogJeXF7Kzs+FwOPDTn/4UdrsdAHDTTTchKSkJx44dw/Lly5GdnY1NmzZhx44d8PDwQHx8PA4cOOAc6/PPP4fRaER6ejq++uorNDU1ifmHJ6KrwiJK9D3f3X/0u759pPro0aN47bXXkJmZCVmWO90CcNCgQTh79izi4uJwww03oKmpCW1tbQCAH//4xwCA0aNHo6amBjabDWfPnnXuv9vY2AibzeYc6+6778bXX3+N2NhYuLm54Ve/+pVi/7xE1HssokTfI0kSgItFsKamBgBw8uRJnD9/HsDFjb0XLFiAkJAQVFZW4uOPP77iOGVlZfjPf/6DjRs3M4rGbgAAARdJREFU4uzZs3jvvfechfjzzz/H7NmzceTIEQwbNgzDhw/HD3/4Q2RlZWHgwIF45513MG7cOBQXFwO4uMn9kCFDkJWVhU8//RSvvPIKcnNzRf9REFE3WESJOjFhwgQMHjwYjzzyCEwmE4YPHw4AWLFiBVavXo2WlhZcuHABq1atuuLvT5o0CX/4wx/w2GOPQZIkBAQE4PTp0wCAEydO4Oc//zlaW1uRlJQEX19fPPHEE4iOjkZHRwduuukm/OQnP3GOFRQUhLi4OLz11ltob2/HkiVLxP8BEFG3uO0fERFRL3GzBSIiol5iESUiIuolFlEiIqJeYhElIiLqJRZRIiKiXmIRJSIi6iUWUSIiol5iESUiIuql/wesxIVQVh1w3wAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "cm = confusion_matrix(np.argmax(true_label, axis=-1), np.argmax(pred_label, axis=-1))\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm / sum(true_label), xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/9k/_qtc2s8x41xbrrfvcsrn72ym0000gn/T/ipykernel_31233/71227727.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfigure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfigsize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Accuracy [train]'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mALPHA\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'#2B2118'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhistory\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'val_accuracy'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Accuracy [val]'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mALPHA\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'#836449'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ALPHA = 1\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['accuracy'], label='Accuracy [train]', alpha=ALPHA, color='#2B2118')\n",
    "plt.plot(history['val_accuracy'], label='Accuracy [val]', alpha=ALPHA, color='#836449')\n",
    "\n",
    "plt.plot(history['precision'], label='Precision [train]', alpha=ALPHA, color='#F04019')\n",
    "plt.plot(history['val_precision'], label='Precision [val]', alpha=ALPHA, color='#F07518')\n",
    "\n",
    "plt.plot(history['recall'], label='Recall [train]', alpha=ALPHA, color='#D2BB60')\n",
    "plt.plot(history['val_recall'], label='Recall [val]', alpha=ALPHA, color='#B3D160')\n",
    "\n",
    "plt.ylim(0.1, 1)\n",
    "plt.title('Results')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Accuracy Graph\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['accuracy'], label='Accuracy [train]', alpha=ALPHA, color='#2B2118')\n",
    "plt.plot(history['val_accuracy'], label='Accuracy [val]', alpha=ALPHA, color='#836449')\n",
    "\n",
    "plt.ylim(.1, 1)\n",
    "plt.title('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Precision Graph\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['precision'], label='Precision [train]', alpha=ALPHA, color='#F04019')\n",
    "plt.plot(history['val_precision'], label='Precision [val]', alpha=ALPHA, color='#F07518')\n",
    "\n",
    "plt.ylim(.1, 1)\n",
    "plt.title('Precision')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Recall Graph\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['recall'], label='Recall Train', alpha=ALPHA, color='#303F9F')\n",
    "plt.plot(history['val_recall'], label='Recall Val', alpha=ALPHA, color='#1976D2')\n",
    "\n",
    "plt.ylim(.5, 1)\n",
    "plt.title('Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loss Graph\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(history['recall'], label='Recall [train]', alpha=ALPHA, color='#D2BB60')\n",
    "plt.plot(history['val_recall'], label='Recall [val]', alpha=ALPHA, color='#B3D160')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "16TOaMkqrjqSOW8YTD4_cbVwwqEK7edNI",
     "timestamp": 1668428132632
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
