{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Custom CNN for image classification\n",
    "### Team: 0Idee (Bono Federico, Cecere Nicola, Zanutto Davide)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries and set seed for reporducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "id": "KNZotXHOapW8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429891880,
     "user_tz": -60,
     "elapsed": 4979,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 09:59:36.474846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras.models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "import splitfolders\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "metadata": {
    "id": "CvMKuJH0apW-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429894425,
     "user_tz": -60,
     "elapsed": 308,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Set log levels\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "id": "bQIJQdcCapW_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429898793,
     "user_tz": -60,
     "elapsed": 214,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data import"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OSFbxo0DapXA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Splitting the main dataset into train and val\n",
    "dataset_dir = './dataset_split'\n",
    "\n",
    "if not (os.path.exists(dataset_dir)):\n",
    "    print('splitting')\n",
    "    splitfolders.ratio('./training_data_final', output=dataset_dir, seed=seed, ratio=(0.8, 0.2))\n",
    "\n",
    "# Setting dataset directories\n",
    "training_dir = os.path.join(dataset_dir, 'train')\n",
    "validation_dir = os.path.join(dataset_dir, 'val')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JVZpBO_bapXD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2829 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "aug_train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    brightness_range=(0.6, 1.4),\n",
    "    zoom_range=0.6,\n",
    "    fill_mode='reflect',\n",
    "    rescale=1. / 255\n",
    ")\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "aug_train_gen = aug_train_data_gen.flow_from_directory(\n",
    "    directory=training_dir,\n",
    "    target_size=(96, 96),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='categorical',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")"
   ],
   "metadata": {
    "id": "ilLddj5LapXG",
    "outputId": "e2f49ece-7c0b-446c-e1a1-2ab420d4b4eb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430279500,
     "user_tz": -60,
     "elapsed": 6,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 713 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data_gen = ImageDataGenerator(rescale=1 / 255.)\n",
    "\n",
    "valid_gen = valid_data_gen.flow_from_directory(\n",
    "    directory=validation_dir,\n",
    "    target_size=(256, 256),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=seed\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model\n",
    "### Parameters and configuration"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4Gc1EGSbapXG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "input_shape = (96, 96, 3)\n",
    "epochs = 200\n",
    "labels = ['Species1', 'Species2', 'Species3', 'Species4', 'Species5', 'Species6', 'Species7', 'Species8']\n",
    "\n",
    "# Weights are based on the number of samples and then fine-tuned on the train dataset\n",
    "class_weights = {0: 2., 1: 1., 2: 1., 3: 1., 4: 1., 5: 2., 6: 1., 7: 1.}"
   ],
   "metadata": {
    "id": "lvv6irhHapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430281738,
     "user_tz": -60,
     "elapsed": 1,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    # Input layer -------------------------------------------------------\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    # First layer -------------------------------------------------------\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(input_layer)\n",
    "    conv1 = tfkl.BatchNormalization()(conv1)\n",
    "    pool1 = tfkl.MaxPooling2D()(conv1)\n",
    "\n",
    "    # Second layer -------------------------------------------------------\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool1)\n",
    "    conv2 = tfkl.BatchNormalization()(conv2)\n",
    "    pool2 = tfkl.MaxPooling2D()(conv2)\n",
    "\n",
    "    # Third layer -------------------------------------------------------\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool2)\n",
    "\n",
    "    # Fourth layer -------------------------------------------------------\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(conv3)\n",
    "    conv4 = tfkl.BatchNormalization()(conv4)\n",
    "    pool3 = tfkl.MaxPooling2D()(conv4)\n",
    "\n",
    "    # Fifth layer -------------------------------------------------------\n",
    "    conv5 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool3)\n",
    "    conv5 = tfkl.BatchNormalization()(conv5)\n",
    "    pool4 = tfkl.MaxPooling2D()(conv5)\n",
    "\n",
    "    # Sixth layer -------------------------------------------------------\n",
    "    conv6 = tfkl.Conv2D(\n",
    "        filters=512,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool4)\n",
    "    conv6 = tfkl.BatchNormalization()(conv6)\n",
    "    pool5 = tfkl.MaxPooling2D()(conv6)\n",
    "\n",
    "    # Flattening layer -------------------------------------------------------\n",
    "    flattening_layer = tfkl.GlobalAvgPool2D(name='gap')(pool5)\n",
    "\n",
    "    # Dense layers -------------------------------------------------------\n",
    "    classifier_layer = tfkl.Dense(units=600, name='Classifier', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                                  activation='relu')(flattening_layer)\n",
    "    hidden_layer = tfkl.Dense(units=258, name='Hidden_layer', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                              activation='relu')(classifier_layer)\n",
    "    dropout = tfkl.Dropout(0.3, seed=seed)(hidden_layer)\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                              name='output_layer')(dropout)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        loss=tfk.losses.CategoricalCrossentropy(),\n",
    "        optimizer=tfk.optimizers.Adam(),\n",
    "        metrics=['accuracy', tfk.metrics.Precision(), tfk.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: AMD Radeon Pro 560X\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 96, 96, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 48, 48, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2D  (None, 512)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Classifier (Dense)          (None, 600)               307800    \n",
      "                                                                 \n",
      " Hidden_layer (Dense)        (None, 258)               155058    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 258)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 8)                 2072      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,185,058\n",
      "Trainable params: 2,183,074\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model (for data augmentation training)\n",
    "model = build_model(input_shape)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fit callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "    exps_dir = os.path.join('data_augmentation_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model checkpoint\n",
    "    # ----------------\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
    "                                                       save_weights_only=True,  # True to save only weights\n",
    "                                                       save_best_only=False)  # True to save only the best epoch\n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Visualize Learning on Tensorboard\n",
    "    # ---------------------------------\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "\n",
    "    # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "    # Early Stopping\n",
    "    # --------------\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "    # Learning Rate Scheduler --------------------------------------------\n",
    "    LRS_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "    callbacks.append(LRS_callback)\n",
    "\n",
    "    return callbacks"
   ],
   "metadata": {
    "id": "QgDzFFTUapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430285936,
     "user_tz": -60,
     "elapsed": 204,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "89/89 [==============================] - 32s 285ms/step - loss: 2.1400 - accuracy: 0.3340 - precision: 0.4303 - recall: 0.1234 - val_loss: 2.2330 - val_accuracy: 0.1529 - val_precision: 0.3483 - val_recall: 0.0982 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 18s 203ms/step - loss: 1.8289 - accuracy: 0.4164 - precision: 0.5847 - recall: 0.1842 - val_loss: 2.1864 - val_accuracy: 0.2202 - val_precision: 0.3217 - val_recall: 0.1417 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 17s 195ms/step - loss: 1.7548 - accuracy: 0.4422 - precision: 0.5861 - recall: 0.2238 - val_loss: 1.8176 - val_accuracy: 0.3464 - val_precision: 0.4549 - val_recall: 0.1627 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 18s 197ms/step - loss: 1.6193 - accuracy: 0.4867 - precision: 0.6430 - recall: 0.2686 - val_loss: 1.6478 - val_accuracy: 0.4081 - val_precision: 0.5547 - val_recall: 0.2132 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 17s 194ms/step - loss: 1.5478 - accuracy: 0.5118 - precision: 0.6625 - recall: 0.3026 - val_loss: 1.8735 - val_accuracy: 0.3015 - val_precision: 0.4205 - val_recall: 0.1038 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 18s 197ms/step - loss: 1.5237 - accuracy: 0.5175 - precision: 0.6743 - recall: 0.3022 - val_loss: 1.6307 - val_accuracy: 0.3619 - val_precision: 0.5839 - val_recall: 0.1318 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 17s 195ms/step - loss: 1.4558 - accuracy: 0.5483 - precision: 0.6976 - recall: 0.3507 - val_loss: 3.3140 - val_accuracy: 0.2258 - val_precision: 0.2444 - val_recall: 0.1529 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 18s 199ms/step - loss: 1.4113 - accuracy: 0.5596 - precision: 0.6929 - recall: 0.3765 - val_loss: 1.8007 - val_accuracy: 0.3843 - val_precision: 0.4522 - val_recall: 0.2258 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 17s 194ms/step - loss: 1.3385 - accuracy: 0.5938 - precision: 0.7205 - recall: 0.4129 - val_loss: 2.3365 - val_accuracy: 0.3338 - val_precision: 0.4011 - val_recall: 0.1964 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 18s 205ms/step - loss: 1.3217 - accuracy: 0.5907 - precision: 0.7341 - recall: 0.4295 - val_loss: 1.6755 - val_accuracy: 0.3899 - val_precision: 0.6743 - val_recall: 0.1655 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 18s 197ms/step - loss: 1.2498 - accuracy: 0.6083 - precision: 0.7377 - recall: 0.4563 - val_loss: 2.4978 - val_accuracy: 0.2511 - val_precision: 0.2873 - val_recall: 0.1459 - lr: 9.0484e-04\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 18s 199ms/step - loss: 1.1863 - accuracy: 0.6310 - precision: 0.7562 - recall: 0.4846 - val_loss: 2.1886 - val_accuracy: 0.3731 - val_precision: 0.5101 - val_recall: 0.2118 - lr: 8.1873e-04\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 18s 199ms/step - loss: 1.1338 - accuracy: 0.6638 - precision: 0.7729 - recall: 0.5125 - val_loss: 2.1485 - val_accuracy: 0.3899 - val_precision: 0.4646 - val_recall: 0.1935 - lr: 7.4082e-04\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 18s 198ms/step - loss: 1.0244 - accuracy: 0.6833 - precision: 0.7911 - recall: 0.5663 - val_loss: 1.8551 - val_accuracy: 0.3282 - val_precision: 0.4889 - val_recall: 0.1543 - lr: 6.7032e-04\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 18s 198ms/step - loss: 1.0530 - accuracy: 0.6801 - precision: 0.7830 - recall: 0.5688 - val_loss: 3.0029 - val_accuracy: 0.3128 - val_precision: 0.3450 - val_recall: 0.2076 - lr: 6.0653e-04\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 18s 205ms/step - loss: 0.9689 - accuracy: 0.6925 - precision: 0.8015 - recall: 0.5882 - val_loss: 2.3574 - val_accuracy: 0.3352 - val_precision: 0.4151 - val_recall: 0.2160 - lr: 5.4881e-04\n"
     ]
    }
   ],
   "source": [
    "# Create folders and callbacks and fit\n",
    "aug_callbacks = create_folders_and_callbacks(model_name='CNN_Aug')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=aug_train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=aug_callbacks,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights\n",
    ").history"
   ],
   "metadata": {
    "id": "EUdsjUfdapXI",
    "outputId": "be5340c2-af75-4003-8380-169b2370318e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431787144,
     "user_tz": -60,
     "elapsed": 1492245,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Save best epoch model\n",
    "model.save(\"data_augmentation_experiments/CNN_Aug_Best\")"
   ],
   "metadata": {
    "id": "up5di_mcapXI",
    "outputId": "9828dc0d-172e-446b-97fe-86433966240e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431799360,
     "user_tz": -60,
     "elapsed": 3030,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results\n",
    "### Confusion matrix, Accuracy, Precision and Recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(32, 256, 256, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [14], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m batch \u001B[38;5;241m=\u001B[39m get_next_batch(valid_gen)\n\u001B[1;32m      5\u001B[0m true_label \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m----> 6\u001B[0m pred_label \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m500\u001B[39m):\n\u001B[1;32m      8\u001B[0m     batch \u001B[38;5;241m=\u001B[39m get_next_batch(valid_gen)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/var/folders/52/p_k1rywx3y19_c8bd_1dh4ym0000gn/T/__autograph_generated_file2bimwd9q.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/nicolacecere/opt/anaconda3/envs/amd_gpu/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 96, 96, 3), found shape=(32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "def get_next_batch(generator):\n",
    "    return next(generator)\n",
    "\n",
    "batch = get_next_batch(valid_gen)\n",
    "true_label = batch[1]\n",
    "pred_label = model.predict(batch[0])\n",
    "for i in range(0, 500):\n",
    "    batch = get_next_batch(valid_gen)\n",
    "    true_label = np.concatenate((true_label, batch[1]), axis=0)\n",
    "    pred_label = np.concatenate((pred_label, model.predict(batch[0])), axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm = confusion_matrix(np.argmax(true_label, axis=-1), np.argmax(pred_label, axis=-1))\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm / sum(true_label), xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ALPHA = 1\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['accuracy'], label='Accuracy [train]', alpha=ALPHA, color='#2B2118')\n",
    "plt.plot(history['val_accuracy'], label='Accuracy [val]', alpha=ALPHA, color='#836449')\n",
    "\n",
    "plt.plot(history['precision'], label='Precision [train]', alpha=ALPHA, color='#F04019')\n",
    "plt.plot(history['val_precision'], label='Precision [val]', alpha=ALPHA, color='#F07518')\n",
    "\n",
    "plt.plot(history['recall'], label='Recall [train]', alpha=ALPHA, color='#D2BB60')\n",
    "plt.plot(history['val_recall'], label='Recall [val]', alpha=ALPHA, color='#B3D160')\n",
    "\n",
    "plt.ylim(0.1, 1)\n",
    "plt.title('Results')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Accuracy Graph\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['accuracy'], label='Accuracy [train]', alpha=ALPHA, color='#2B2118')\n",
    "plt.plot(history['val_accuracy'], label='Accuracy [val]', alpha=ALPHA, color='#836449')\n",
    "\n",
    "plt.ylim(.1, 1)\n",
    "plt.title('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Precision Graph\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['precision'], label='Precision [train]', alpha=ALPHA, color='#F04019')\n",
    "plt.plot(history['val_precision'], label='Precision [val]', alpha=ALPHA, color='#F07518')\n",
    "\n",
    "plt.ylim(.1, 1)\n",
    "plt.title('Precision')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Recall Graph\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.plot(history['recall'], label='Recall Train', alpha=ALPHA, color='#303F9F')\n",
    "plt.plot(history['val_recall'], label='Recall Val', alpha=ALPHA, color='#1976D2')\n",
    "\n",
    "plt.ylim(.5, 1)\n",
    "plt.title('Recall')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loss Graph\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(history['recall'], label='Recall [train]', alpha=ALPHA, color='#D2BB60')\n",
    "plt.plot(history['val_recall'], label='Recall [val]', alpha=ALPHA, color='#B3D160')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.title('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "16TOaMkqrjqSOW8YTD4_cbVwwqEK7edNI",
     "timestamp": 1668428132632
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}