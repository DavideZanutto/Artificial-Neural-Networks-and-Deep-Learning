{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3FoTyRa9pLu"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f_sOaV1Y8NsL"
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLb-N5JzUUQS"
   },
   "source": [
    "### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C7HYua8HUHIj"
   },
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Suppress warnings"
   ],
   "metadata": {
    "id": "7yyZaEAH4PZM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "id": "P_SmiYRG4O0L"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uEZnG9FLIAQR"
   },
   "source": [
    "# Download the data\n",
    "dataset = 'C:/Users/39342/Downloads/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data'\n",
    "training = 'C:/Users/39342/Downloads/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data/training'\n",
    "test = 'C:/Users/39342/Downloads/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data/test'\n",
    "validation = 'C:/Users/39342/Downloads/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data/validation'"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HftmCCnssm6O"
   },
   "source": [
    "labels = {\n",
    "    0:'species1',\n",
    "    1:'species2',\n",
    "    2:'species3',\n",
    "    3:'species4',\n",
    "    4:'species5',\n",
    "    5:'species6',\n",
    "    6:'species7',\n",
    "    7:'species8'\n",
    "}"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opLBOnWjWqay"
   },
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2835 images belonging to 8 classes.\n",
      "Found 398 images belonging to 8 classes.\n",
      "Found 475 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Images are divided into folders, one for each class.\n",
    "# If the images are organized in such a way, we can exploit the\n",
    "# ImageDataGenerator to read them from disk.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator for training, validation, and test sets\n",
    "train_data_gen = ImageDataGenerator()\n",
    "valid_data_gen = ImageDataGenerator()\n",
    "test_data_gen = ImageDataGenerator()\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "train_gen = train_data_gen.flow_from_directory(directory=training,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed\n",
    "                                               )\n",
    "valid_gen = train_data_gen.flow_from_directory(directory=validation,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)\n",
    "test_gen = train_data_gen.flow_from_directory(directory=test,\n",
    "                                              target_size=(96,96),\n",
    "                                              color_mode='rgb',\n",
    "                                              classes=None, # can be set to labels\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=32,\n",
    "                                              shuffle=False,\n",
    "                                              seed=seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2835 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "aug_train_data_gen = ImageDataGenerator(rotation_range=20,\n",
    "                                        horizontal_flip= True,\n",
    "                                        vertical_flip= True,\n",
    "                                        brightness_range=(0.6,1.4),\n",
    "                                        zoom_range=0.6,\n",
    "                                        fill_mode='nearest',\n",
    "                                        rescale=1./255) # rescale value is multiplied to the image\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "aug_train_gen = aug_train_data_gen.flow_from_directory(directory=training,\n",
    "                                                       target_size=(96,96),\n",
    "                                                       color_mode='rgb',\n",
    "                                                       classes=None, # can be set to labels\n",
    "                                                       class_mode='categorical',\n",
    "                                                       batch_size=32,\n",
    "                                                       shuffle=True,\n",
    "                                                       seed=seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr9CX7CYdBg_"
   },
   "source": [
    "### Models metadata"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7YcxBMJhl4EM"
   },
   "source": [
    "input_shape = (96, 96, 3)\n",
    "batch_size = 64\n",
    "epochs = 200"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXmw4F0wlY0h"
   },
   "source": [
    "### Standard model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRlz7PE5_OEo"
   },
   "source": [
    "### Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GBSheIJZrpfU"
   },
   "source": [
    "# Download and plot the VGG16 model\n",
    "supernet = tfk.applications.VGG16(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(64,64,3)\n",
    ")\n",
    "supernet.summary()\n",
    "tfk.utils.plot_model(supernet)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 64, 64, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 16, 16, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 8, 8, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i-Mkoyd5_WU5"
   },
   "source": [
    "# Use the supernet as feature extractor\n",
    "supernet.trainable = False\n",
    "\n",
    "inputs = tfk.Input(shape=(32,32,3))\n",
    "x = tfkl.Resizing(64, 64, interpolation=\"bicubic\")(inputs)\n",
    "x = supernet(x)\n",
    "x = tfkl.Flatten(name='Flattening')(x)\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "x = tfkl.Dense(\n",
    "    256, \n",
    "    activation='relu',\n",
    "    kernel_initializer = tfk.initializers.HeUniform(seed))(x)\n",
    "x = tfkl.Dropout(0.3, seed=seed)(x)\n",
    "outputs = tfkl.Dense(\n",
    "    8,\n",
    "    activation='softmax',\n",
    "    kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
    "\n",
    "\n",
    "# Connect input and output through the Model class\n",
    "tl_model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "\n",
    "# Compile the model\n",
    "tl_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "tl_model.summary()"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " resizing_1 (Resizing)       (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 2, 2, 512)         14714688  \n",
      "                                                                 \n",
      " Flattening (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,241,288\n",
      "Trainable params: 526,600\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z-7i-2abn4Vd",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Train the model\n",
    "tl_history = tl_model.fit(\n",
    "    x = train_gen,\n",
    "    batch_size = 64,\n",
    "    epochs = 200,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",
    ").history"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "89/89 [==============================] - 71s 773ms/step - loss: 8.1700 - accuracy: 0.3309 - val_loss: 1.7475 - val_accuracy: 0.4296\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 69s 773ms/step - loss: 2.0093 - accuracy: 0.3954 - val_loss: 1.5980 - val_accuracy: 0.4271\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 66s 746ms/step - loss: 1.5881 - accuracy: 0.4469 - val_loss: 1.4647 - val_accuracy: 0.5101\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 68s 759ms/step - loss: 1.4259 - accuracy: 0.4981 - val_loss: 1.4843 - val_accuracy: 0.5126\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 67s 755ms/step - loss: 1.3399 - accuracy: 0.5079 - val_loss: 1.4650 - val_accuracy: 0.4698\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 68s 760ms/step - loss: 1.2740 - accuracy: 0.5383 - val_loss: 1.4808 - val_accuracy: 0.5176\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 70s 792ms/step - loss: 1.2436 - accuracy: 0.5534 - val_loss: 1.3811 - val_accuracy: 0.5276\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 69s 774ms/step - loss: 1.1885 - accuracy: 0.5654 - val_loss: 1.4441 - val_accuracy: 0.5427\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 66s 739ms/step - loss: 1.1137 - accuracy: 0.5866 - val_loss: 1.4409 - val_accuracy: 0.5377\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 66s 739ms/step - loss: 1.0507 - accuracy: 0.6095 - val_loss: 1.4595 - val_accuracy: 0.5402\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 66s 737ms/step - loss: 1.0333 - accuracy: 0.6250 - val_loss: 1.4569 - val_accuracy: 0.5578\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 66s 741ms/step - loss: 1.0013 - accuracy: 0.6279 - val_loss: 1.4633 - val_accuracy: 0.5477\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 67s 751ms/step - loss: 0.9839 - accuracy: 0.6321 - val_loss: 1.4009 - val_accuracy: 0.5226\n",
      "Epoch 14/200\n",
      "62/89 [===================>..........] - ETA: 18s - loss: 0.9555 - accuracy: 0.6352"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bIZ9iwNEfF2b"
   },
   "source": [
    "# Predict the test set with the CNN\n",
    "predictions = tl_model.predict(test_gen)\n",
    "predictions.shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ELY3uf7kslCu"
   },
   "source": [
    "# Save the best model\n",
    "tl_model.save('TransferLearningModel')\n",
    "del tl_model"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBwf91PEfcJ_"
   },
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PfPJePumjRjp"
   },
   "source": [
    "# Re-load the model after transfer learning\n",
    "ft_model = tfk.models.load_model('TransferLearningModel')\n",
    "ft_model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2zjBB3hO_OSI"
   },
   "source": [
    "# Set all VGG layers to True\n",
    "ft_model.get_layer('vgg16').trainable = True\n",
    "for i, layer in enumerate(ft_model.get_layer('vgg16').layers):\n",
    "   print(i, layer.name, layer.trainable)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uKb0_D2tCSrZ"
   },
   "source": [
    "# Freeze first N layers, e.g., until 14th\n",
    "for i, layer in enumerate(ft_model.get_layer('vgg16').layers[:14]):\n",
    "  layer.trainable=False\n",
    "for i, layer in enumerate(ft_model.get_layer('vgg16').layers):\n",
    "   print(i, layer.name, layer.trainable)\n",
    "ft_model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Kb3wq2DNFgCZ"
   },
   "source": [
    "# Compile the model\n",
    "ft_model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics='accuracy')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gReRof3iferf"
   },
   "source": [
    "# Fine-tune the model\n",
    "ft_history = ft_model.fit(\n",
    "    x = X_train_ft,\n",
    "    y = y_train,\n",
    "    batch_size = 256,\n",
    "    epochs = 200,\n",
    "    validation_data = (X_val_ft, y_val),\n",
    "    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True)]\n",
    ").history"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BnG-gxQTIdkr"
   },
   "source": [
    "# Plot the training\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(standard_history['loss'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(standard_history['val_loss'], label='Standard', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(tl_history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\n",
    "plt.plot(tl_history['val_loss'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n",
    "plt.plot(ft_history['loss'], alpha=.3, color='#2ABC3D', linestyle='--')\n",
    "plt.plot(ft_history['val_loss'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Categorical Crossentropy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(standard_history['accuracy'], alpha=.3, color='#ff7f0e', linestyle='--')\n",
    "plt.plot(standard_history['val_accuracy'], label='Standard', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(tl_history['accuracy'], alpha=.3, color='#4D61E2', linestyle='--')\n",
    "plt.plot(tl_history['val_accuracy'], label='Transfer Learning', alpha=.8, color='#4D61E2')\n",
    "plt.plot(ft_history['accuracy'], alpha=.3, color='#2ABC3D', linestyle='--')\n",
    "plt.plot(ft_history['val_accuracy'], label='Fine Tuning', alpha=.8, color='#2ABC3D')\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Accuracy')\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kFfM7vSfJMPo"
   },
   "source": [
    "# Predict the test set with the CNN\n",
    "predictions = ft_model.predict(X_test_tf)\n",
    "predictions.shape\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
    "\n",
    "# Compute the classification metrics\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1))\n",
    "precision = precision_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "recall = recall_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "f1 = f1_score(np.argmax(y_test, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "print('Accuracy:',accuracy.round(4))\n",
    "print('Precision:',precision.round(4))\n",
    "print('Recall:',recall.round(4))\n",
    "print('F1:',f1.round(4))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm.T, xticklabels=list(labels.values()), yticklabels=list(labels.values()))\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YEJT9OVttR0C"
   },
   "source": [
    "ft_model.save('FineTuningModel')\n",
    "del ft_model"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
