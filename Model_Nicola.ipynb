{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "id": "KNZotXHOapW8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429891880,
     "user_tz": -60,
     "elapsed": 4979,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   },
   "outputs": [],
   "source": [
    "import keras.models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "metadata": {
    "id": "CvMKuJH0apW-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429894425,
     "user_tz": -60,
     "elapsed": 308,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "id": "bQIJQdcCapW_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429898793,
     "user_tz": -60,
     "elapsed": 214,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OSFbxo0DapXA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "dataset_dir = './SplitData/data'\n",
    "training_dir = './SplitData/data/training'\n",
    "validation_dir = './SplitData/data/validation'\n",
    "test_dir = './SplitData/data/test'"
   ],
   "metadata": {
    "id": "Jq6Y5CcYapXA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430262602,
     "user_tz": -60,
     "elapsed": 2,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2835 images belonging to 8 classes.\n",
      "Found 398 images belonging to 8 classes.\n",
      "Found 495 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Images are divided into folders, one for each class.\n",
    "# If the images are organized in such a way, we can exploit the\n",
    "# ImageDataGenerator to read them from disk.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator for training, validation, and test sets\n",
    "train_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "valid_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                               target_size=(96, 96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None,  # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed\n",
    "                                               )\n",
    "valid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(96, 96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None,  # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)\n",
    "test_gen = train_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                              target_size=(96, 96),\n",
    "                                              color_mode='rgb',\n",
    "                                              classes=None,  # can be set to labels\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=32,\n",
    "                                              shuffle=False,\n",
    "                                              seed=seed)"
   ],
   "metadata": {
    "id": "Jbjo4RcvapXC",
    "outputId": "147f6090-320c-4954-e997-0acf1aee2fd5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430272236,
     "user_tz": -60,
     "elapsed": 6763,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JVZpBO_bapXD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.preprocessing.image.ImageDataGenerator at 0x7f9cc8f8d550>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, samplewise_center=False,\n",
    "    featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "    zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n",
    "    height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
    "    channel_shift_range=0.0, fill_mode='nearest', cval=0.0,\n",
    "    horizontal_flip=False, vertical_flip=False, rescale=None,\n",
    "    preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None\n",
    ")"
   ],
   "metadata": {
    "id": "6YrWUsdmapXE",
    "outputId": "7d3549f0-1f80-4cbd-fa12-d7f941a79b80",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430277948,
     "user_tz": -60,
     "elapsed": 232,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2835 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "aug_train_data_gen = ImageDataGenerator(rotation_range=20,\n",
    "                                        horizontal_flip=True,\n",
    "                                        vertical_flip=True,\n",
    "                                        brightness_range=(0.6, 1.4),\n",
    "                                        zoom_range=0.6,\n",
    "                                        fill_mode='nearest',\n",
    "                                        rescale=1. / 255)  # rescale value is multiplied to the image\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "aug_train_gen = aug_train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                                       target_size=(96, 96),\n",
    "                                                       color_mode='rgb',\n",
    "                                                       classes=None,  # can be set to labels\n",
    "                                                       class_mode='categorical',\n",
    "                                                       batch_size=32,\n",
    "                                                       shuffle=True,\n",
    "                                                       seed=seed)"
   ],
   "metadata": {
    "id": "ilLddj5LapXG",
    "outputId": "e2f49ece-7c0b-446c-e1a1-2ab420d4b4eb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430279500,
     "user_tz": -60,
     "elapsed": 6,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4Gc1EGSbapXG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "input_shape = (96, 96, 3)\n",
    "epochs = 200"
   ],
   "metadata": {
    "id": "lvv6irhHapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430281738,
     "user_tz": -60,
     "elapsed": 1,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = {0: 2., 1: 1., 2: 1., 3: 1., 4: 1., 5: 2., 6: 1., 7: 1.}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(input_layer)\n",
    "    pool1 = tfkl.MaxPooling2D()(conv1)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool1)\n",
    "    pool2 = tfkl.MaxPooling2D()(conv2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool2)\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(conv3)\n",
    "    pool3 = tfkl.MaxPooling2D()(conv4)\n",
    "\n",
    "    conv5 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool3)\n",
    "    pool4 = tfkl.MaxPooling2D()(conv5)\n",
    "\n",
    "    conv6 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation='relu',\n",
    "        kernel_initializer=tfk.initializers.HeUniform(seed)\n",
    "    )(pool4)\n",
    "    pool5 = tfkl.MaxPooling2D()(conv6)\n",
    "\n",
    "    flattening_layer = tfkl.GlobalAvgPool2D(name='gap')(pool5)\n",
    "    dropout = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
    "    classifier_layer = tfkl.Dense(units=256, name='Classifier', kernel_initializer=tfk.initializers.HeUniform(seed),\n",
    "                                  activation='relu')(dropout)\n",
    "    dropout = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed),\n",
    "                              name='output_layer')(dropout)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "    exps_dir = os.path.join('data_augmentation_experiments')\n",
    "    if not os.path.exists(exps_dir):\n",
    "        os.makedirs(exps_dir)\n",
    "\n",
    "    now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "    if not os.path.exists(exp_dir):\n",
    "        os.makedirs(exp_dir)\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Model checkpoint\n",
    "    # ----------------\n",
    "    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
    "                                                       save_weights_only=True,  # True to save only weights\n",
    "                                                       save_best_only=False)  # True to save only the best epoch\n",
    "    callbacks.append(ckpt_callback)\n",
    "\n",
    "    # Visualize Learning on Tensorboard\n",
    "    # ---------------------------------\n",
    "    tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "    if not os.path.exists(tb_dir):\n",
    "        os.makedirs(tb_dir)\n",
    "\n",
    "    # By default shows losses and metrics for both training and validation\n",
    "    tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                                 profile_batch=0,\n",
    "                                                 histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "    callbacks.append(tb_callback)\n",
    "\n",
    "    # Early Stopping\n",
    "    # --------------\n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    callbacks.append(es_callback)\n",
    "\n",
    "    return callbacks"
   ],
   "metadata": {
    "id": "QgDzFFTUapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430285936,
     "user_tz": -60,
     "elapsed": 204,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 48, 48, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 24, 24, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 12, 12, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 3, 3, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2D  (None, 256)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " Classifier (Dense)          (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,193,928\n",
      "Trainable params: 1,193,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model (for data augmentation training)\n",
    "model = build_model(input_shape)\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "FEkYSrT2apXI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430289188,
     "user_tz": -60,
     "elapsed": 526,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "89/89 [==============================] - 11s 111ms/step - loss: 2.9943 - accuracy: 0.1072 - val_loss: 2.0767 - val_accuracy: 0.1206\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 2.8487 - accuracy: 0.1566 - val_loss: 2.0197 - val_accuracy: 0.2563\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 2.7230 - accuracy: 0.2120 - val_loss: 1.7996 - val_accuracy: 0.2563\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 8s 90ms/step - loss: 2.7248 - accuracy: 0.2049 - val_loss: 2.0683 - val_accuracy: 0.2487\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 2.6184 - accuracy: 0.2705 - val_loss: 1.9145 - val_accuracy: 0.2889\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 2.5204 - accuracy: 0.3323 - val_loss: 1.7328 - val_accuracy: 0.3593\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 2.4367 - accuracy: 0.3386 - val_loss: 1.7246 - val_accuracy: 0.3518\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 2.3704 - accuracy: 0.3538 - val_loss: 1.6335 - val_accuracy: 0.3945\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 2.3087 - accuracy: 0.3760 - val_loss: 1.4743 - val_accuracy: 0.4095\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 8s 86ms/step - loss: 2.2732 - accuracy: 0.3827 - val_loss: 1.4852 - val_accuracy: 0.4648\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 2.2429 - accuracy: 0.4042 - val_loss: 1.5229 - val_accuracy: 0.4573\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 2.2496 - accuracy: 0.3979 - val_loss: 1.7782 - val_accuracy: 0.3844\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 8s 87ms/step - loss: 2.2019 - accuracy: 0.4120 - val_loss: 1.4300 - val_accuracy: 0.4673\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 8s 88ms/step - loss: 2.1498 - accuracy: 0.4289 - val_loss: 1.5680 - val_accuracy: 0.4196\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 2.0836 - accuracy: 0.4413 - val_loss: 1.4209 - val_accuracy: 0.4673\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 2.0514 - accuracy: 0.4451 - val_loss: 1.4463 - val_accuracy: 0.4598\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 2.0162 - accuracy: 0.4575 - val_loss: 1.5088 - val_accuracy: 0.4598\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 1.9959 - accuracy: 0.4519 - val_loss: 1.3661 - val_accuracy: 0.4724\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 2.0265 - accuracy: 0.4480 - val_loss: 1.4653 - val_accuracy: 0.4774\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 1.9247 - accuracy: 0.4790 - val_loss: 1.2157 - val_accuracy: 0.4573\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 1.9354 - accuracy: 0.4882 - val_loss: 1.1476 - val_accuracy: 0.5377\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.8616 - accuracy: 0.5136 - val_loss: 1.4105 - val_accuracy: 0.4698\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 9s 97ms/step - loss: 1.8182 - accuracy: 0.5256 - val_loss: 1.4404 - val_accuracy: 0.4673\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.8363 - accuracy: 0.5277 - val_loss: 1.3496 - val_accuracy: 0.5050\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 1.8031 - accuracy: 0.5284 - val_loss: 1.1841 - val_accuracy: 0.5201\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 1.7230 - accuracy: 0.5587 - val_loss: 1.1851 - val_accuracy: 0.5176\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.6854 - accuracy: 0.5626 - val_loss: 1.1459 - val_accuracy: 0.5452\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 1.7197 - accuracy: 0.5541 - val_loss: 1.1468 - val_accuracy: 0.5226\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 10s 114ms/step - loss: 1.6986 - accuracy: 0.5566 - val_loss: 1.1924 - val_accuracy: 0.5653\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.6658 - accuracy: 0.5563 - val_loss: 1.2369 - val_accuracy: 0.5251\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 9s 99ms/step - loss: 1.6276 - accuracy: 0.5778 - val_loss: 1.2471 - val_accuracy: 0.5176\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.6024 - accuracy: 0.5820 - val_loss: 1.1110 - val_accuracy: 0.5779\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.6261 - accuracy: 0.5813 - val_loss: 1.1816 - val_accuracy: 0.5528\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.5906 - accuracy: 0.5915 - val_loss: 1.0486 - val_accuracy: 0.6106\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.6106 - accuracy: 0.5859 - val_loss: 1.1076 - val_accuracy: 0.5678\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 1.5778 - accuracy: 0.5866 - val_loss: 1.1972 - val_accuracy: 0.5678\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 1.5593 - accuracy: 0.5993 - val_loss: 1.1902 - val_accuracy: 0.5779\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.5661 - accuracy: 0.5820 - val_loss: 1.1151 - val_accuracy: 0.5653\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.4696 - accuracy: 0.6190 - val_loss: 1.2081 - val_accuracy: 0.5477\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 9s 100ms/step - loss: 1.4733 - accuracy: 0.6198 - val_loss: 1.3148 - val_accuracy: 0.5327\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 9s 101ms/step - loss: 1.4339 - accuracy: 0.6367 - val_loss: 1.2998 - val_accuracy: 0.5678\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 10s 109ms/step - loss: 1.4509 - accuracy: 0.6198 - val_loss: 0.9741 - val_accuracy: 0.6156\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 9s 106ms/step - loss: 1.4491 - accuracy: 0.6176 - val_loss: 0.9413 - val_accuracy: 0.6432\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 9s 105ms/step - loss: 1.4276 - accuracy: 0.6201 - val_loss: 0.9972 - val_accuracy: 0.6256\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 10s 107ms/step - loss: 1.4603 - accuracy: 0.6176 - val_loss: 1.1407 - val_accuracy: 0.5704\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 10s 108ms/step - loss: 1.3587 - accuracy: 0.6494 - val_loss: 1.2286 - val_accuracy: 0.5653\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 10s 107ms/step - loss: 1.3821 - accuracy: 0.6399 - val_loss: 0.9998 - val_accuracy: 0.6432\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 9s 104ms/step - loss: 1.3599 - accuracy: 0.6476 - val_loss: 1.0202 - val_accuracy: 0.6432\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.4597 - accuracy: 0.6155 - val_loss: 1.0846 - val_accuracy: 0.5955\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.3249 - accuracy: 0.6607 - val_loss: 1.1196 - val_accuracy: 0.5930\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 9s 102ms/step - loss: 1.3388 - accuracy: 0.6480 - val_loss: 1.1679 - val_accuracy: 0.5829\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 1.3362 - accuracy: 0.6494 - val_loss: 1.2484 - val_accuracy: 0.5854\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 9s 103ms/step - loss: 1.3162 - accuracy: 0.6646 - val_loss: 1.0613 - val_accuracy: 0.6181\n"
     ]
    }
   ],
   "source": [
    "# Create folders and callbacks and fit\n",
    "aug_callbacks = create_folders_and_callbacks(model_name='CNN_Aug')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x=aug_train_gen,\n",
    "    epochs=epochs,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=aug_callbacks,\n",
    "    batch_size=32,\n",
    "    class_weight=class_weights\n",
    ").history"
   ],
   "metadata": {
    "id": "EUdsjUfdapXI",
    "outputId": "be5340c2-af75-4003-8380-169b2370318e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431787144,
     "user_tz": -60,
     "elapsed": 1492245,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Save best epoch model\n",
    "model.save(\"data_augmentation_experiments/CNN_Aug_Best\")"
   ],
   "metadata": {
    "id": "up5di_mcapXI",
    "outputId": "9828dc0d-172e-446b-97fe-86433966240e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431799360,
     "user_tz": -60,
     "elapsed": 3030,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 30ms/step - loss: 0.8971 - accuracy: 0.6828\n",
      "\n",
      "Test metrics with data augmentation\n",
      "{'loss': 0.8970720171928406, 'accuracy': 0.6828283071517944}\n"
     ]
    }
   ],
   "source": [
    "# Trained with data augmentation\n",
    "model_aug = tfk.models.load_model(\"data_augmentation_experiments/CNN_Aug_Best\")\n",
    "model_aug_test_metrics = model_aug.evaluate(test_gen, return_dict=True)\n",
    "\n",
    "print()\n",
    "print(\"Test metrics with data augmentation\")\n",
    "print(model_aug_test_metrics)\n"
   ],
   "metadata": {
    "id": "NYFv3JpWapXJ",
    "outputId": "7b05027c-379e-4d92-d399-a4cf6a691d31",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431881358,
     "user_tz": -60,
     "elapsed": 78439,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "16TOaMkqrjqSOW8YTD4_cbVwwqEK7edNI",
     "timestamp": 1668428132632
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
