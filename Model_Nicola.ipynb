{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "id": "KNZotXHOapW8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429891880,
     "user_tz": -60,
     "elapsed": 4979,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   },
   "outputs": [],
   "source": [
    "import keras.models\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from PIL import Image\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ],
   "metadata": {
    "id": "CvMKuJH0apW-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429894425,
     "user_tz": -60,
     "elapsed": 308,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "tf.get_logger().setLevel('INFO')\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ],
   "metadata": {
    "id": "bQIJQdcCapW_",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668429898793,
     "user_tz": -60,
     "elapsed": 214,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OSFbxo0DapXA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "dataset_dir = '/Users/nicolacecere/GitHub/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data'\n",
    "training_dir = '/Users/nicolacecere/GitHub/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data/training'\n",
    "validation_dir = '/Users/nicolacecere/GitHub/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data/validation'\n",
    "test_dir = '/Users/nicolacecere/GitHub/Artificial-Neural-Networks-and-Deep-Learning/SplitData/data/test'"
   ],
   "metadata": {
    "id": "Jq6Y5CcYapXA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430262602,
     "user_tz": -60,
     "elapsed": 2,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2835 images belonging to 8 classes.\n",
      "Found 398 images belonging to 8 classes.\n",
      "Found 495 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Images are divided into folders, one for each class.\n",
    "# If the images are organized in such a way, we can exploit the\n",
    "# ImageDataGenerator to read them from disk.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an instance of ImageDataGenerator for training, validation, and test sets\n",
    "train_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "valid_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "train_gen = train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed\n",
    "                                               )\n",
    "valid_gen = train_data_gen.flow_from_directory(directory=validation_dir,\n",
    "                                               target_size=(96,96),\n",
    "                                               color_mode='rgb',\n",
    "                                               classes=None, # can be set to labels\n",
    "                                               class_mode='categorical',\n",
    "                                               batch_size=32,\n",
    "                                               shuffle=True,\n",
    "                                               seed=seed)\n",
    "test_gen = train_data_gen.flow_from_directory(directory=test_dir,\n",
    "                                              target_size=(96,96),\n",
    "                                              color_mode='rgb',\n",
    "                                              classes=None, # can be set to labels\n",
    "                                              class_mode='categorical',\n",
    "                                              batch_size=32,\n",
    "                                              shuffle=False,\n",
    "                                              seed=seed)"
   ],
   "metadata": {
    "id": "Jbjo4RcvapXC",
    "outputId": "147f6090-320c-4954-e997-0acf1aee2fd5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430272236,
     "user_tz": -60,
     "elapsed": 6763,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JVZpBO_bapXD"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [],
   "source": [
    "def get_next_batch(generator):\n",
    "  batch = next(generator)\n",
    "\n",
    "  image = batch[0]\n",
    "  target = batch[1]\n",
    "\n",
    "  print(\"(Input) image shape:\", image.shape)\n",
    "  print(\"Target shape:\",target.shape)\n",
    "\n",
    "  # Visualize only the first sample\n",
    "  image = image[0]\n",
    "  target = target[0]\n",
    "  target_idx = np.argmax(target)\n",
    "  print()\n",
    "  print(\"Categorical label:\", target)\n",
    "  print(\"Label:\", target_idx)\n",
    "  print(\"Class name:\", labels[target_idx])\n",
    "  fig = plt.figure(figsize=(6, 4))\n",
    "  plt.imshow(np.uint8(image))\n",
    "\n",
    "  return batch"
   ],
   "metadata": {
    "id": "vbpCbuL4apXE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430276200,
     "user_tz": -60,
     "elapsed": 209,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "<keras.preprocessing.image.ImageDataGenerator at 0x7fac0ea76fe0>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=False, samplewise_center=False,\n",
    "    featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "    zca_whitening=False, zca_epsilon=1e-06, rotation_range=0, width_shift_range=0.0,\n",
    "    height_shift_range=0.0, brightness_range=None, shear_range=0.0, zoom_range=0.0,\n",
    "    channel_shift_range=0.0, fill_mode='nearest', cval=0.0,\n",
    "    horizontal_flip=False, vertical_flip=False, rescale=None,\n",
    "    preprocessing_function=None, data_format=None, validation_split=0.0, dtype=None\n",
    ")"
   ],
   "metadata": {
    "id": "6YrWUsdmapXE",
    "outputId": "7d3549f0-1f80-4cbd-fa12-d7f941a79b80",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430277948,
     "user_tz": -60,
     "elapsed": 232,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2835 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ImageDataGenerator with Data Augmentation\n",
    "aug_train_data_gen = ImageDataGenerator(rotation_range=25,\n",
    "                                        horizontal_flip= True,\n",
    "                                        vertical_flip= True,\n",
    "                                        brightness_range=(0.2,1.8),\n",
    "                                        zoom_range=0.2,\n",
    "                                        fill_mode='nearest',\n",
    "                                        rescale=1./255) # rescale value is multiplied to the image\n",
    "\n",
    "# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\n",
    "aug_train_gen = aug_train_data_gen.flow_from_directory(directory=training_dir,\n",
    "                                                       target_size=(96,96),\n",
    "                                                       color_mode='rgb',\n",
    "                                                       classes=None, # can be set to labels\n",
    "                                                       class_mode='categorical',\n",
    "                                                       batch_size=32,\n",
    "                                                       shuffle=True,\n",
    "                                                       seed=seed)"
   ],
   "metadata": {
    "id": "ilLddj5LapXG",
    "outputId": "e2f49ece-7c0b-446c-e1a1-2ab420d4b4eb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430279500,
     "user_tz": -60,
     "elapsed": 6,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "4Gc1EGSbapXG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "input_shape = (96, 96, 3)\n",
    "epochs = 200"
   ],
   "metadata": {
    "id": "lvv6irhHapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430281738,
     "user_tz": -60,
     "elapsed": 1,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    model = tfk.models.Sequential()\n",
    "\n",
    "    model.add(tfk.layers.Conv2D(16, kernel_size=1, input_shape=input_shape, padding='same', activation='relu'))\n",
    "    model.add(tfk.layers.Conv2D(32, kernel_size=1, padding='same', activation='relu'))\n",
    "    model.add(tfk.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(tfk.layers.Conv2D(32, kernel_size=3, input_shape=input_shape, padding='same', activation='relu'))\n",
    "    model.add(tfk.layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'))\n",
    "    model.add(tfk.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(tfk.layers.Flatten())\n",
    "    model.add(tfk.layers.Dropout(rate=0.2))\n",
    "    model.add(tfk.layers.Dense(64, activation='relu'))\n",
    "    model.add(tfk.layers.Dense(32, activation='relu'))\n",
    "    model.add(tfk.layers.Dense(8, activation='softmax', name='output'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "id": "5cMI2gMWapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430283586,
     "user_tz": -60,
     "elapsed": 391,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "\n",
    "    conv1 = tfkl.Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(input_layer)\n",
    "    pool1 = tfkl.MaxPooling2D()(conv1)\n",
    "\n",
    "    conv2 = tfkl.Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool1)\n",
    "    pool2 = tfkl.MaxPooling2D()(conv2)\n",
    "\n",
    "    conv3 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool2)\n",
    "    conv4 = tfkl.Conv2D(\n",
    "        filters=128,\n",
    "        kernel_size=3,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(conv3)\n",
    "    pool3 = tfkl.MaxPooling2D()(conv4)\n",
    "\n",
    "    conv5 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool3)\n",
    "    pool4 = tfkl.MaxPooling2D()(conv5)\n",
    "\n",
    "    conv6 = tfkl.Conv2D(\n",
    "        filters=256,\n",
    "        kernel_size=3,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
    "    )(pool4)\n",
    "    pool5 = tfkl.GlobalAveragePooling2D(name='gap')(conv6)\n",
    "\n",
    "    flattening_layer = tfkl.Flatten(name='Flatten')(pool5)\n",
    "    dropout = tfkl.Dropout(0.2, seed=seed)(flattening_layer)\n",
    "    classifier_layer = tfkl.Dense(units=256, name='Classifier', kernel_initializer=tfk.initializers.HeUniform(seed), activation='relu')(dropout)\n",
    "    dropout = tfkl.Dropout(0.2, seed=seed)(classifier_layer)\n",
    "    output_layer = tfkl.Dense(units=8, activation='softmax', kernel_initializer=tfk.initializers.GlorotUniform(seed), name='output_layer')(dropout)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name):\n",
    "\n",
    "  exps_dir = os.path.join('data_augmentation_experiments')\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "\n",
    "  callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'),\n",
    "                                                     save_weights_only=True, # True to save only weights\n",
    "                                                     save_best_only=False) # True to save only the best epoch\n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "\n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "\n",
    "  # Early Stopping\n",
    "  # --------------\n",
    "  es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "  callbacks.append(es_callback)\n",
    "\n",
    "  return callbacks"
   ],
   "metadata": {
    "id": "QgDzFFTUapXH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430285936,
     "user_tz": -60,
     "elapsed": 204,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_186 (Conv2D)         (None, 96, 96, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_133 (MaxPooli  (None, 48, 48, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (None, 48, 48, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_134 (MaxPooli  (None, 24, 24, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_135 (MaxPooli  (None, 12, 12, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_136 (MaxPooli  (None, 6, 6, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 6, 6, 256)         590080    \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2D  (None, 256)              0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " Flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " Classifier (Dense)          (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 8)                 2056      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,193,928\n",
      "Trainable params: 1,193,928\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model (for data augmentation training)\n",
    "model = build_model(input_shape)\n",
    "model.summary()"
   ],
   "metadata": {
    "id": "FEkYSrT2apXI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668430289188,
     "user_tz": -60,
     "elapsed": 526,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "89/89 [==============================] - 27s 302ms/step - loss: 2.0684 - accuracy: 0.1869 - val_loss: 2.4208 - val_accuracy: 0.1608\n",
      "Epoch 2/200\n",
      "89/89 [==============================] - 25s 281ms/step - loss: 1.9052 - accuracy: 0.2430 - val_loss: 1.9857 - val_accuracy: 0.1432\n",
      "Epoch 3/200\n",
      "89/89 [==============================] - 25s 279ms/step - loss: 1.8219 - accuracy: 0.2765 - val_loss: 2.3907 - val_accuracy: 0.1432\n",
      "Epoch 4/200\n",
      "89/89 [==============================] - 25s 277ms/step - loss: 1.7728 - accuracy: 0.2871 - val_loss: 2.4205 - val_accuracy: 0.1884\n",
      "Epoch 5/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 1.7136 - accuracy: 0.3266 - val_loss: 2.6281 - val_accuracy: 0.2337\n",
      "Epoch 6/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 1.6365 - accuracy: 0.3580 - val_loss: 2.2590 - val_accuracy: 0.1633\n",
      "Epoch 7/200\n",
      "89/89 [==============================] - 26s 291ms/step - loss: 1.5894 - accuracy: 0.3852 - val_loss: 2.0664 - val_accuracy: 0.2136\n",
      "Epoch 8/200\n",
      "89/89 [==============================] - 27s 303ms/step - loss: 1.4840 - accuracy: 0.4229 - val_loss: 2.2217 - val_accuracy: 0.2186\n",
      "Epoch 9/200\n",
      "89/89 [==============================] - 27s 307ms/step - loss: 1.4535 - accuracy: 0.4205 - val_loss: 1.8882 - val_accuracy: 0.3643\n",
      "Epoch 10/200\n",
      "89/89 [==============================] - 28s 309ms/step - loss: 1.4178 - accuracy: 0.4519 - val_loss: 2.5743 - val_accuracy: 0.1935\n",
      "Epoch 11/200\n",
      "89/89 [==============================] - 29s 320ms/step - loss: 1.3510 - accuracy: 0.4653 - val_loss: 2.3222 - val_accuracy: 0.2739\n",
      "Epoch 12/200\n",
      "89/89 [==============================] - 27s 299ms/step - loss: 1.3471 - accuracy: 0.4723 - val_loss: 2.3263 - val_accuracy: 0.2487\n",
      "Epoch 13/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 1.3387 - accuracy: 0.4818 - val_loss: 1.9999 - val_accuracy: 0.3015\n",
      "Epoch 14/200\n",
      "89/89 [==============================] - 29s 323ms/step - loss: 1.2527 - accuracy: 0.5125 - val_loss: 1.7306 - val_accuracy: 0.3116\n",
      "Epoch 15/200\n",
      "89/89 [==============================] - 26s 291ms/step - loss: 1.2800 - accuracy: 0.5118 - val_loss: 1.5868 - val_accuracy: 0.3844\n",
      "Epoch 16/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 1.2373 - accuracy: 0.5160 - val_loss: 2.3527 - val_accuracy: 0.2864\n",
      "Epoch 17/200\n",
      "89/89 [==============================] - 28s 312ms/step - loss: 1.2354 - accuracy: 0.5295 - val_loss: 1.4226 - val_accuracy: 0.4497\n",
      "Epoch 18/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 1.2065 - accuracy: 0.5319 - val_loss: 1.7556 - val_accuracy: 0.3342\n",
      "Epoch 19/200\n",
      "89/89 [==============================] - 27s 297ms/step - loss: 1.1422 - accuracy: 0.5605 - val_loss: 2.3637 - val_accuracy: 0.3970\n",
      "Epoch 20/200\n",
      "89/89 [==============================] - 26s 295ms/step - loss: 1.1284 - accuracy: 0.5623 - val_loss: 1.8227 - val_accuracy: 0.4296\n",
      "Epoch 21/200\n",
      "89/89 [==============================] - 26s 294ms/step - loss: 1.1345 - accuracy: 0.5810 - val_loss: 2.1304 - val_accuracy: 0.2965\n",
      "Epoch 22/200\n",
      "89/89 [==============================] - 26s 288ms/step - loss: 1.1260 - accuracy: 0.5707 - val_loss: 1.6328 - val_accuracy: 0.4548\n",
      "Epoch 23/200\n",
      "89/89 [==============================] - 28s 316ms/step - loss: 1.1006 - accuracy: 0.5901 - val_loss: 1.7936 - val_accuracy: 0.3844\n",
      "Epoch 24/200\n",
      "89/89 [==============================] - 26s 296ms/step - loss: 1.0820 - accuracy: 0.5838 - val_loss: 1.6793 - val_accuracy: 0.4296\n",
      "Epoch 25/200\n",
      "89/89 [==============================] - 26s 294ms/step - loss: 1.0409 - accuracy: 0.6113 - val_loss: 2.0215 - val_accuracy: 0.3894\n",
      "Epoch 26/200\n",
      "89/89 [==============================] - 26s 293ms/step - loss: 1.0252 - accuracy: 0.6152 - val_loss: 1.9032 - val_accuracy: 0.3844\n",
      "Epoch 27/200\n",
      "89/89 [==============================] - 26s 290ms/step - loss: 1.0485 - accuracy: 0.6056 - val_loss: 1.5159 - val_accuracy: 0.4523\n",
      "Epoch 28/200\n",
      "89/89 [==============================] - 26s 290ms/step - loss: 1.0254 - accuracy: 0.6145 - val_loss: 2.2825 - val_accuracy: 0.3442\n",
      "Epoch 29/200\n",
      "89/89 [==============================] - 29s 324ms/step - loss: 0.9782 - accuracy: 0.6325 - val_loss: 2.2631 - val_accuracy: 0.3819\n",
      "Epoch 30/200\n",
      "89/89 [==============================] - 31s 346ms/step - loss: 0.9662 - accuracy: 0.6314 - val_loss: 2.0116 - val_accuracy: 0.3894\n",
      "Epoch 31/200\n",
      "89/89 [==============================] - 26s 294ms/step - loss: 0.9824 - accuracy: 0.6286 - val_loss: 1.8668 - val_accuracy: 0.4045\n",
      "Epoch 32/200\n",
      "89/89 [==============================] - 25s 277ms/step - loss: 0.9618 - accuracy: 0.6441 - val_loss: 1.7409 - val_accuracy: 0.4573\n",
      "Epoch 33/200\n",
      "89/89 [==============================] - 25s 278ms/step - loss: 0.9209 - accuracy: 0.6688 - val_loss: 2.0802 - val_accuracy: 0.4296\n",
      "Epoch 34/200\n",
      "89/89 [==============================] - 26s 287ms/step - loss: 0.9172 - accuracy: 0.6568 - val_loss: 1.7727 - val_accuracy: 0.4472\n",
      "Epoch 35/200\n",
      "89/89 [==============================] - 28s 315ms/step - loss: 0.9227 - accuracy: 0.6564 - val_loss: 1.4052 - val_accuracy: 0.4774\n",
      "Epoch 36/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 0.9090 - accuracy: 0.6670 - val_loss: 1.6416 - val_accuracy: 0.4799\n",
      "Epoch 37/200\n",
      "89/89 [==============================] - 27s 305ms/step - loss: 0.9105 - accuracy: 0.6614 - val_loss: 1.7104 - val_accuracy: 0.4623\n",
      "Epoch 38/200\n",
      "89/89 [==============================] - 27s 308ms/step - loss: 0.8721 - accuracy: 0.6871 - val_loss: 1.8970 - val_accuracy: 0.4347\n",
      "Epoch 39/200\n",
      "89/89 [==============================] - 28s 309ms/step - loss: 0.8745 - accuracy: 0.6734 - val_loss: 1.5052 - val_accuracy: 0.4673\n",
      "Epoch 40/200\n",
      "89/89 [==============================] - 26s 292ms/step - loss: 0.8345 - accuracy: 0.6959 - val_loss: 1.4448 - val_accuracy: 0.5126\n",
      "Epoch 41/200\n",
      "89/89 [==============================] - 24s 268ms/step - loss: 0.8439 - accuracy: 0.6952 - val_loss: 1.7140 - val_accuracy: 0.4899\n",
      "Epoch 42/200\n",
      "89/89 [==============================] - 25s 280ms/step - loss: 0.8266 - accuracy: 0.6956 - val_loss: 2.4909 - val_accuracy: 0.4447\n",
      "Epoch 43/200\n",
      "89/89 [==============================] - 25s 280ms/step - loss: 0.8119 - accuracy: 0.7079 - val_loss: 1.3123 - val_accuracy: 0.5402\n",
      "Epoch 44/200\n",
      "89/89 [==============================] - 27s 301ms/step - loss: 0.8000 - accuracy: 0.7051 - val_loss: 2.2423 - val_accuracy: 0.4146\n",
      "Epoch 45/200\n",
      "89/89 [==============================] - 26s 293ms/step - loss: 0.7984 - accuracy: 0.7002 - val_loss: 1.8045 - val_accuracy: 0.4573\n",
      "Epoch 46/200\n",
      "89/89 [==============================] - 26s 288ms/step - loss: 0.7612 - accuracy: 0.7153 - val_loss: 1.5034 - val_accuracy: 0.5327\n",
      "Epoch 47/200\n",
      "89/89 [==============================] - 26s 286ms/step - loss: 0.7500 - accuracy: 0.7259 - val_loss: 2.0441 - val_accuracy: 0.4146\n",
      "Epoch 48/200\n",
      "89/89 [==============================] - 26s 289ms/step - loss: 0.7197 - accuracy: 0.7379 - val_loss: 1.6613 - val_accuracy: 0.5477\n",
      "Epoch 49/200\n",
      "89/89 [==============================] - 26s 288ms/step - loss: 0.7655 - accuracy: 0.7309 - val_loss: 2.2243 - val_accuracy: 0.4497\n",
      "Epoch 50/200\n",
      "89/89 [==============================] - 26s 286ms/step - loss: 0.6846 - accuracy: 0.7499 - val_loss: 2.2190 - val_accuracy: 0.4623\n",
      "Epoch 51/200\n",
      "89/89 [==============================] - 26s 287ms/step - loss: 0.7328 - accuracy: 0.7287 - val_loss: 1.9666 - val_accuracy: 0.4749\n",
      "Epoch 52/200\n",
      "89/89 [==============================] - 25s 284ms/step - loss: 0.6856 - accuracy: 0.7457 - val_loss: 1.8247 - val_accuracy: 0.4925\n",
      "Epoch 53/200\n",
      "89/89 [==============================] - 25s 285ms/step - loss: 0.7107 - accuracy: 0.7390 - val_loss: 1.7708 - val_accuracy: 0.5503\n",
      "Epoch 54/200\n",
      "89/89 [==============================] - 26s 287ms/step - loss: 0.6682 - accuracy: 0.7457 - val_loss: 2.1657 - val_accuracy: 0.4975\n",
      "Epoch 55/200\n",
      "89/89 [==============================] - 26s 286ms/step - loss: 0.6763 - accuracy: 0.7450 - val_loss: 2.1175 - val_accuracy: 0.4849\n",
      "Epoch 56/200\n",
      "89/89 [==============================] - 26s 288ms/step - loss: 0.6591 - accuracy: 0.7640 - val_loss: 1.8151 - val_accuracy: 0.4925\n",
      "Epoch 57/200\n",
      "89/89 [==============================] - 26s 288ms/step - loss: 0.6937 - accuracy: 0.7422 - val_loss: 2.5099 - val_accuracy: 0.3945\n",
      "Epoch 58/200\n",
      "89/89 [==============================] - 26s 286ms/step - loss: 0.6509 - accuracy: 0.7577 - val_loss: 1.9368 - val_accuracy: 0.4472\n",
      "Epoch 59/200\n",
      "89/89 [==============================] - 25s 285ms/step - loss: 0.6420 - accuracy: 0.7573 - val_loss: 1.6173 - val_accuracy: 0.5327\n",
      "Epoch 60/200\n",
      "89/89 [==============================] - 26s 286ms/step - loss: 0.6084 - accuracy: 0.7845 - val_loss: 2.0640 - val_accuracy: 0.5327\n",
      "Epoch 61/200\n",
      "89/89 [==============================] - 26s 286ms/step - loss: 0.6160 - accuracy: 0.7690 - val_loss: 1.8883 - val_accuracy: 0.5226\n",
      "Epoch 62/200\n",
      "89/89 [==============================] - 27s 303ms/step - loss: 0.6059 - accuracy: 0.7778 - val_loss: 1.9203 - val_accuracy: 0.5201\n",
      "Epoch 63/200\n",
      "89/89 [==============================] - 27s 301ms/step - loss: 0.6120 - accuracy: 0.7658 - val_loss: 1.7458 - val_accuracy: 0.5528\n",
      "Epoch 64/200\n",
      "89/89 [==============================] - 28s 308ms/step - loss: 0.5627 - accuracy: 0.7887 - val_loss: 3.7870 - val_accuracy: 0.3769\n",
      "Epoch 65/200\n",
      "89/89 [==============================] - 29s 319ms/step - loss: 0.5832 - accuracy: 0.7764 - val_loss: 1.6955 - val_accuracy: 0.5427\n",
      "Epoch 66/200\n",
      "89/89 [==============================] - 29s 322ms/step - loss: 0.5670 - accuracy: 0.7838 - val_loss: 1.2776 - val_accuracy: 0.5804\n",
      "Epoch 67/200\n",
      "89/89 [==============================] - 28s 317ms/step - loss: 0.5479 - accuracy: 0.7982 - val_loss: 1.3085 - val_accuracy: 0.5754\n",
      "Epoch 68/200\n",
      "89/89 [==============================] - 29s 326ms/step - loss: 0.5787 - accuracy: 0.7831 - val_loss: 2.4101 - val_accuracy: 0.4824\n",
      "Epoch 69/200\n",
      "89/89 [==============================] - 29s 325ms/step - loss: 0.5695 - accuracy: 0.7898 - val_loss: 1.7208 - val_accuracy: 0.5352\n",
      "Epoch 70/200\n",
      "89/89 [==============================] - 28s 311ms/step - loss: 0.5236 - accuracy: 0.8042 - val_loss: 2.2183 - val_accuracy: 0.4874\n",
      "Epoch 71/200\n",
      "89/89 [==============================] - 26s 287ms/step - loss: 0.4794 - accuracy: 0.8314 - val_loss: 2.0829 - val_accuracy: 0.4975\n",
      "Epoch 72/200\n",
      "89/89 [==============================] - 27s 306ms/step - loss: 0.5457 - accuracy: 0.8078 - val_loss: 1.6745 - val_accuracy: 0.5528\n",
      "Epoch 73/200\n",
      "89/89 [==============================] - 26s 293ms/step - loss: 0.5236 - accuracy: 0.8155 - val_loss: 1.5843 - val_accuracy: 0.5603\n",
      "Epoch 74/200\n",
      "89/89 [==============================] - 27s 302ms/step - loss: 0.5037 - accuracy: 0.8159 - val_loss: 2.4480 - val_accuracy: 0.4523\n",
      "Epoch 75/200\n",
      "89/89 [==============================] - 24s 271ms/step - loss: 0.4692 - accuracy: 0.8265 - val_loss: 1.9075 - val_accuracy: 0.5578\n",
      "Epoch 76/200\n",
      "89/89 [==============================] - 24s 264ms/step - loss: 0.5209 - accuracy: 0.8106 - val_loss: 1.5094 - val_accuracy: 0.5804\n"
     ]
    }
   ],
   "source": [
    "# Create folders and callbacks and fit\n",
    "aug_callbacks = create_folders_and_callbacks(model_name='CNN_Aug')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = aug_train_gen,\n",
    "    epochs = epochs,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = aug_callbacks,\n",
    "    batch_size=32\n",
    ").history"
   ],
   "metadata": {
    "id": "EUdsjUfdapXI",
    "outputId": "be5340c2-af75-4003-8380-169b2370318e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431787144,
     "user_tz": -60,
     "elapsed": 1492245,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# Save best epoch model\n",
    "model.save(\"data_augmentation_experiments/CNN_Aug_Best\")"
   ],
   "metadata": {
    "id": "up5di_mcapXI",
    "outputId": "9828dc0d-172e-446b-97fe-86433966240e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431799360,
     "user_tz": -60,
     "elapsed": 3030,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 63ms/step - loss: 1.2413 - accuracy: 0.6545\n",
      "\n",
      "Test metrics with data augmentation\n",
      "{'loss': 1.2413262128829956, 'accuracy': 0.6545454263687134}\n"
     ]
    }
   ],
   "source": [
    "# Trained with data augmentation\n",
    "model_aug = tfk.models.load_model(\"data_augmentation_experiments/CNN_Aug_Best\")\n",
    "model_aug_test_metrics = model_aug.evaluate(test_gen, return_dict=True)\n",
    "\n",
    "print()\n",
    "print(\"Test metrics with data augmentation\")\n",
    "print(model_aug_test_metrics)\n"
   ],
   "metadata": {
    "id": "NYFv3JpWapXJ",
    "outputId": "7b05027c-379e-4d92-d399-a4cf6a691d31",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668431881358,
     "user_tz": -60,
     "elapsed": 78439,
     "user": {
      "displayName": "Nicola Cecere",
      "userId": "15930624256794819808"
     }
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "\n",
    "batch = next(train_gen)"
   ],
   "metadata": {
    "id": "cC4m5OQTapXJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([6])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = tf.io.read_file('{}/training/{}/{}'.format(dataset_dir, \"Species7\", \"00002.jpg\"))\n",
    "img = tf.io.decode_jpeg(img, channels=3)\n",
    "\n",
    "out = model_aug.predict(tf.expand_dims(img, 0))\n",
    "out = tf.argmax(out, axis=-1)\n",
    "\n",
    "out.numpy()"
   ],
   "metadata": {
    "id": "Rx8I7RxBapXJ",
    "outputId": "2c6fc7ce-f32f-4ab7-bafd-e13e705bc683"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "16TOaMkqrjqSOW8YTD4_cbVwwqEK7edNI",
     "timestamp": 1668428132632
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
