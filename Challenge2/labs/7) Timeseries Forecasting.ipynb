{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmKMLFLdfdhL"
   },
   "source": [
    "### Connect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIPnkn7fcGLp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyPYQ85XffFB"
   },
   "outputs": [],
   "source": [
    "%cd /gdrive/My Drive/AN2DL/ExerciseSession7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap3o8JayfgEM"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CesUrUpUtKTp"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfIcXow5tRUY"
   },
   "source": [
    "### Set seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LDmmEgOtKsO"
   },
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a49TrZ82D-Fl"
   },
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YB1vxLkYyfFQ"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('AirQuality.csv')\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f75FMAA1CNA2"
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXpSLGgC902P"
   },
   "outputs": [],
   "source": [
    "def inspect_dataframe(df, columns):\n",
    "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n",
    "    for i, col in enumerate(columns):\n",
    "        axs[i].plot(df[col])\n",
    "        axs[i].set_title(col)\n",
    "    plt.show()\n",
    "inspect_dataframe(dataset, dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUqW6PgmNsem"
   },
   "source": [
    "Sequential Train-Test split and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wB4jRVsPJw25"
   },
   "outputs": [],
   "source": [
    "test_size = 3800\n",
    "X_train_raw = dataset.iloc[:-test_size]\n",
    "# y_train_raw = y.iloc[:-test_size]\n",
    "X_test_raw = dataset.iloc[-test_size:]\n",
    "# y_test_raw = y.iloc[-test_size:]\n",
    "print(X_train_raw.shape, X_test_raw.shape)\n",
    "\n",
    "# Normalize both features and labels\n",
    "X_min = X_train_raw.min()\n",
    "X_max = X_train_raw.max()\n",
    "\n",
    "X_train_raw = (X_train_raw-X_min)/(X_max-X_min)\n",
    "X_test_raw = (X_test_raw-X_min)/(X_max-X_min)\n",
    "\n",
    "plt.figure(figsize=(17,5))\n",
    "plt.plot(X_train_raw.temperature, label='Train (temperature)')\n",
    "plt.plot(X_test_raw.temperature, label='Test (temperature)')\n",
    "plt.title('Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5U5QeKoWJP9X"
   },
   "outputs": [],
   "source": [
    "window = 100\n",
    "stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n0ckE6LaO68r"
   },
   "outputs": [],
   "source": [
    "future = dataset[-window:]\n",
    "future = (future-X_min)/(X_max-X_min)\n",
    "future = np.expand_dims(future, axis=0)\n",
    "future.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFoJa5kMkq2g"
   },
   "outputs": [],
   "source": [
    "def build_sequences(df, target_labels=['temperature'], window=200, stride=20, telescope=100):\n",
    "    # Sanity check to avoid runtime errors\n",
    "    assert window % stride == 0\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    temp_df = df.copy().values\n",
    "    temp_label = df[target_labels].copy().values\n",
    "    padding_len = len(df)%window\n",
    "\n",
    "    if(padding_len != 0):\n",
    "        # Compute padding length\n",
    "        padding_len = window - len(df)%window\n",
    "        padding = np.zeros((padding_len,temp_df.shape[1]), dtype='float32')\n",
    "        temp_df = np.concatenate((padding,df))\n",
    "        padding = np.zeros((padding_len,temp_label.shape[1]), dtype='float32')\n",
    "        temp_label = np.concatenate((padding,temp_label))\n",
    "        assert len(temp_df) % window == 0\n",
    "\n",
    "    for idx in np.arange(0,len(temp_df)-window-telescope,stride):\n",
    "        dataset.append(temp_df[idx:idx+window])\n",
    "        labels.append(temp_label[idx+window:idx+window+telescope])\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "    return dataset, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgY5g6xUDswZ"
   },
   "source": [
    "### Multivariate Forecating (Direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jU3_acq542V-"
   },
   "outputs": [],
   "source": [
    "target_labels = dataset.columns\n",
    "telescope = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_dsZ1Mb41DH"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\n",
    "X_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, telescope)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruqsimHHmqzJ"
   },
   "outputs": [],
   "source": [
    "def inspect_multivariate(X, y, columns, telescope, idx=None):\n",
    "    if(idx==None):\n",
    "        idx=np.random.randint(0,len(X))\n",
    "\n",
    "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n",
    "    for i, col in enumerate(columns):\n",
    "        axs[i].plot(np.arange(len(X[0,:,i])), X[idx,:,i])\n",
    "        axs[i].scatter(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), y[idx,:,i], color='orange')\n",
    "        axs[i].set_title(col)\n",
    "        axs[i].set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKVNgYSmDxp4"
   },
   "outputs": [],
   "source": [
    "inspect_multivariate(X_train, y_train, target_labels, telescope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AASFwzzCCGNn"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]\n",
    "batch_size = 64\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r38MQcU4phAB"
   },
   "outputs": [],
   "source": [
    "def build_CONV_LSTM_model(input_shape, output_shape):\n",
    "    # Build the neural network layer by layer\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='input_layer')\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True, name='lstm'), name='bidirectional_lstm')(input_layer)\n",
    "    x = tfkl.Conv1D(128, 3, padding='same', activation='relu', name='conv')(x)\n",
    "    if output_shape[0] == 1:\n",
    "        output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same', activation='sigmoid', name='output_layer')(x)\n",
    "        output_layer = tfkl.GlobalAveragePooling1D(keepdims=True, name='gap')(output_layer)\n",
    "    else:\n",
    "        output_layer = tfkl.Conv1D(output_shape[1], 3, padding='same', activation='sigmoid', name='output_layer')(x)\n",
    "        crop_size = (output_layer.shape[1]-output_shape[0])//2\n",
    "        output_layer = tfkl.Cropping1D((crop_size,crop_size), name='cropping')(output_layer)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=['mae'])\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhAmgJKZCGIl"
   },
   "outputs": [],
   "source": [
    "model = build_CONV_LSTM_model(input_shape, output_shape)\n",
    "model.summary()\n",
    "tfk.utils.plot_model(model, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eIM0f0SCGF3"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_split=.1,\n",
    "    callbacks = [\n",
    "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
    "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLUlKfK0CGDg"
   },
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history['val_loss'])\n",
    "plt.figure(figsize=(17,4))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Squared Error (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(17,4))\n",
    "plt.plot(history['mae'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_mae'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,3))\n",
    "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TD4twq6I5x60"
   },
   "outputs": [],
   "source": [
    "# model.save('DirectForecasting')\n",
    "model = tfk.models.load_model('DirectForecasting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dra5HA3nYq3_"
   },
   "source": [
    "Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA0dgfA452CW"
   },
   "outputs": [],
   "source": [
    "# Predict the test set \n",
    "predictions = model.predict(X_test, verbose=0)\n",
    "print(predictions.shape)\n",
    "\n",
    "mean_squared_error = tfk.metrics.mse(y_test.flatten(),predictions.flatten())\n",
    "mean_absolute_error = tfk.metrics.mae(y_test.flatten(),predictions.flatten())\n",
    "mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlwGA3y3my3P"
   },
   "outputs": [],
   "source": [
    "def inspect_multivariate_prediction(X, y, pred, columns, telescope, idx=None):\n",
    "    if(idx==None):\n",
    "        idx=np.random.randint(0,len(X))\n",
    "\n",
    "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17,17))\n",
    "    for i, col in enumerate(columns):\n",
    "        axs[i].plot(np.arange(len(X[0,:,i])), X[idx,:,i])\n",
    "        axs[i].plot(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), y[idx,:,i], color='orange')\n",
    "        axs[i].plot(np.arange(len(X[0,:,i]), len(X_train[0,:,i])+telescope), pred[idx,:,i], color='green')\n",
    "        axs[i].set_title(col)\n",
    "        axs[i].set_ylim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sPAejWAS5-6p"
   },
   "outputs": [],
   "source": [
    "inspect_multivariate_prediction(X_test, y_test, predictions, target_labels, telescope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t4XqWMtYmOr"
   },
   "source": [
    "Predict the future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CAAKq2c2Q3ic"
   },
   "outputs": [],
   "source": [
    "maes = []\n",
    "for i in range(predictions.shape[1]):\n",
    "    ft_maes = []\n",
    "    for j in range(predictions.shape[2]):\n",
    "        ft_maes.append(np.mean(np.abs(y_test[:,i,j]-predictions[:,i,j]), axis=0))\n",
    "    ft_maes = np.array(ft_maes)\n",
    "    maes.append(ft_maes)\n",
    "maes = np.array(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Or-0IBVfR7CE"
   },
   "outputs": [],
   "source": [
    "future_predictions = model.predict(future,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFmCGZ7c_Jmj"
   },
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(len(target_labels), 1, sharex=True, figsize=(17,17))\n",
    "for i, col in enumerate(target_labels):\n",
    "    axs[i].plot(np.arange(len(future[0,:,i])), future[0,:,i])\n",
    "    axs[i].plot(np.arange(len(future[0,:,i]), len(future[0,:,i])+telescope), future_predictions[0,:,i], color='orange')\n",
    "    axs[i].fill_between(\n",
    "        np.arange(len(future[0,:,i]), len(future[0,:,i])+telescope), \n",
    "        future_predictions[0,:,i]+maes[:,i], \n",
    "        future_predictions[0,:,i]-maes[:,i], \n",
    "        color='orange', alpha=.3)\n",
    "    axs[i].set_title(col)\n",
    "    # axs[i].set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2rCOIN6B2HH"
   },
   "source": [
    "### Multivariate Forecasting (Autoregression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0R6tcsM3N3nA"
   },
   "outputs": [],
   "source": [
    "target_labels = dataset.columns\n",
    "telescope = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4xJuWwzN3ke"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\n",
    "X_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, telescope)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuNjY7sAN3h5"
   },
   "outputs": [],
   "source": [
    "inspect_multivariate(X_train, y_train, target_labels, telescope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2Yt6BHsN3fi"
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]\n",
    "batch_size = 64\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Imfm2jAyN3dV"
   },
   "outputs": [],
   "source": [
    "model = build_CONV_LSTM_model(input_shape, output_shape)\n",
    "model.summary()\n",
    "tfk.utils.plot_model(model, expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EQelVz_N3aw"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    batch_size = batch_size,\n",
    "    epochs = epochs,\n",
    "    validation_split=.1,\n",
    "    callbacks = [\n",
    "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, restore_best_weights=True),\n",
    "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.1, min_lr=1e-5)\n",
    "    ]\n",
    ").history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uv0LtUq2N3Yb"
   },
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(history['val_loss'])\n",
    "plt.figure(figsize=(17,4))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Squared Error (Loss)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(17,4))\n",
    "plt.plot(history['mae'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n",
    "plt.plot(history['val_mae'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.title('Mean Absolute Error')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,3))\n",
    "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
    "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzrO1z8eN3WG"
   },
   "outputs": [],
   "source": [
    "# model.save('AuroregressiveForecasting')\n",
    "model = tfk.models.load_model('AuroregressiveForecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "naY5VlaMN3T0"
   },
   "outputs": [],
   "source": [
    "# Predict the test set \n",
    "predictions = model.predict(X_test,verbose=0)\n",
    "print(predictions.shape)\n",
    "\n",
    "mean_squared_error = tfk.metrics.mse(y_test.flatten(),predictions.flatten())\n",
    "mean_absolute_error = tfk.metrics.mae(y_test.flatten(),predictions.flatten())\n",
    "mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jlU7ONjcJ0s"
   },
   "outputs": [],
   "source": [
    "reg_telescope = 100\n",
    "X_test_reg, y_test_reg = build_sequences(X_test_raw, target_labels, window, stride, reg_telescope)\n",
    "X_test_reg.shape, y_test_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cK-1eJsRcRFy"
   },
   "outputs": [],
   "source": [
    "# Autoregressive Forecasting\n",
    "reg_predictions = np.array([])\n",
    "X_temp = X_test_reg\n",
    "for reg in range(0,reg_telescope,telescope):\n",
    "    pred_temp = model.predict(X_temp,verbose=0)\n",
    "    if(len(reg_predictions)==0):\n",
    "        reg_predictions = pred_temp\n",
    "    else:\n",
    "        reg_predictions = np.concatenate((reg_predictions,pred_temp),axis=1)\n",
    "    X_temp = np.concatenate((X_temp[:,telescope:,:],pred_temp), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8lk2vcocRDi"
   },
   "outputs": [],
   "source": [
    "mean_squared_error = tfk.metrics.mse(y_test_reg.flatten(),reg_predictions.flatten())\n",
    "mean_absolute_error = tfk.metrics.mae(y_test_reg.flatten(),reg_predictions.flatten())\n",
    "mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqb0cQwHcRAt"
   },
   "outputs": [],
   "source": [
    "inspect_multivariate_prediction(X_test_reg, y_test_reg, reg_predictions, target_labels, reg_telescope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFHoq8aIqKDB"
   },
   "source": [
    "predict the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3McV7dejqJnB"
   },
   "outputs": [],
   "source": [
    "maes = []\n",
    "for i in range(reg_predictions.shape[1]):\n",
    "    ft_maes = []\n",
    "    for j in range(reg_predictions.shape[2]):\n",
    "        ft_maes.append(np.mean(np.abs(y_test_reg[:,i,j]-reg_predictions[:,i,j]), axis=0))\n",
    "    ft_maes = np.array(ft_maes)\n",
    "    maes.append(ft_maes)\n",
    "maes = np.array(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVxky8kvqWLh"
   },
   "outputs": [],
   "source": [
    "# Autoregressive Forecasting (Future)\n",
    "reg_future = np.array([])\n",
    "X_temp = future # The sequence to forecast\n",
    "for reg in range(0,reg_telescope,telescope): # For each telescope step (i.e., reg_telescope%telescope is preferred to be 0)\n",
    "    pred_temp = model.predict(X_temp,verbose=0) # Predict the current sequence\n",
    "    if(len(reg_future)==0):\n",
    "        reg_future = pred_temp # Initialize the forecasting\n",
    "    else:\n",
    "        reg_future = np.concatenate((reg_future,pred_temp),axis=1) # Append the prediction to the whole forecasting\n",
    "    X_temp = np.concatenate((X_temp[:,telescope:,:],pred_temp), axis=1) # Shift the input of the next predict so that the just predicted sequence is at the end of the input, and the dimention is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmiZjfDpqjnl"
   },
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(len(target_labels), 1, sharex=True, figsize=(17,17))\n",
    "for i, col in enumerate(target_labels):\n",
    "    axs[i].plot(np.arange(len(future[0,:,i])), future[0,:,i])\n",
    "    axs[i].plot(np.arange(len(future[0,:,i]), len(future[0,:,i])+reg_telescope), reg_future[0,:,i], color='orange')\n",
    "    axs[i].fill_between(\n",
    "        np.arange(len(future[0,:,i]), len(future[0,:,i])+reg_telescope), \n",
    "        reg_future[0,:,i]+maes[:,i], \n",
    "        reg_future[0,:,i]-maes[:,i], \n",
    "        color='orange', alpha=.3)\n",
    "    axs[i].set_title(col)\n",
    "    axs[i].set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9F9n52Up53Y"
   },
   "source": [
    "### Attention Is All You Need"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "Z9F9n52Up53Y"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
